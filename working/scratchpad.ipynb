{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import datetime\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory paths\n",
    "PATHS = {\n",
    "    \"proj\": \"/mnt/coredata/processing/leads\",\n",
    "}\n",
    "PATHS[\"data\"] = op.join(PATHS[\"proj\"], \"data\")\n",
    "PATHS[\"metadata\"] = op.join(PATHS[\"proj\"], \"metadata\")\n",
    "PATHS[\"newdata\"] = op.join(PATHS[\"proj\"], \"newdata\")\n",
    "PATHS[\"raw\"] = op.join(PATHS[\"data\"], \"raw\")\n",
    "PATHS[\"processed\"] = op.join(PATHS[\"data\"], \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_raw(raw_dir, verbose=True):\n",
    "    \"\"\"Scrape raw directory for all nifti files and parse them.\n",
    "\n",
    "    Returns a pandas DataFrame with columns:\n",
    "    - subj: subject ID\n",
    "    - scan_date: scan date (YYYY-MM-DD)\n",
    "    - scan_type: scan type (MRI modality or PET tracer)\n",
    "    - raw_petf: full path to the nifti file in raw\n",
    "    \"\"\"\n",
    "    raw_scans = glob(op.join(raw_dir, \"**\", \"*.nii\"), recursive=True)\n",
    "\n",
    "    output = []\n",
    "    for scanf in raw_scans:\n",
    "        subj = _get_subj(scanf, raw_dir)\n",
    "        scan_date = _get_scan_date(scanf)\n",
    "        scan_type = _get_scan_type(scanf)\n",
    "        output.append([subj, scan_date, scan_type, scanf])\n",
    "\n",
    "    cols = [\"subj\", \"scan_date\", \"scan_type\", \"raw_petf\"]\n",
    "    output = pd.DataFrame(output, columns=cols)\n",
    "\n",
    "    # Add FDG to scan type for LONI files that don't save \"FDG\" in filename\n",
    "    output.loc[output[\"scan_type\"].isnull(), \"scan_type\"] = output.loc[\n",
    "        output[\"scan_type\"].isnull(), \"raw_petf\"\n",
    "    ].apply(lambda x: \"FDG\" if (op.join(raw_dir, \"fdg\") in x) else np.nan)\n",
    "\n",
    "    if verbose:\n",
    "        if len(output) == 0:\n",
    "            print(\"No scans found in raw\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"Found {len(output)} scans from {output['subj'].nunique()} subjects in {raw_dir}\"\n",
    "            )\n",
    "    return output\n",
    "\n",
    "\n",
    "def _get_subj(filepath, raw_dir):\n",
    "    \"\"\"Return the subject ID from filepath to the recon'd nifti.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        The filepath to the reconstructed nifti.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    subj : str\n",
    "        The subject ID parsed from the input file basename.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        subj = filepath.replace(raw_dir + \"/\", \"\").split(\"/\")[1]\n",
    "        if len(subj) > 0:\n",
    "            return subj\n",
    "        else:\n",
    "            return np.nan\n",
    "    except IndexError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def _get_scan_date(filepath):\n",
    "    \"\"\"Return the scan date from filepath to the recon'd nifti.\n",
    "\n",
    "    Iterates over filepath directories from right to left until it finds\n",
    "    a filename or directory whose first 10 characters matches the date\n",
    "    format YYYY-MM-DD.\n",
    "\n",
    "    Returns np.nan if no scan date is found, otherwise a string like\n",
    "    'YYYY-MM-DD'.\n",
    "    \"\"\"\n",
    "    for d in filepath.split(op.sep)[::-1]:\n",
    "        try:\n",
    "            acqdate = check_dt_fmt(d[:10], raise_error=True)\n",
    "            return acqdate\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def check_dt_fmt(datestr, raise_error=False):\n",
    "    \"\"\"Return datestr if formatted like YYYY-MM-DD.\n",
    "\n",
    "    If raise_error is True, raise a ValueError if datestr is not\n",
    "    formatted like YYYY-MM-DD. Otherwise return np.nan.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        datestr_to_datetime(datestr)\n",
    "        return datestr\n",
    "    except ValueError:\n",
    "        if raise_error:\n",
    "            raise ValueError(f\"{datestr} is not formatted like YYYY-MM-DD\")\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "def datestr_to_datetime(datestr):\n",
    "    \"\"\"Convert a date string to a datetime object.\"\"\"\n",
    "    return datetime.datetime.strptime(datestr, \"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def datetime_to_datestr(dt):\n",
    "    \"\"\"Convert a datetime object to a date string.\"\"\"\n",
    "    return dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def _get_scan_type(filepath, scan_type_map_file=None):\n",
    "    \"\"\"Parse the filepath and return the scan type.\"\"\"\n",
    "    if scan_type_map_file is None:\n",
    "        scan_type_map_file = op.join(\n",
    "            PATHS[\"metadata\"], \"ssheets\", \"scan_types_and_tracers.csv\"\n",
    "        )\n",
    "    scan_type_map = (\n",
    "        pd.read_csv(scan_type_map_file).set_index(\"name_in\")[\"name_out\"].to_dict()\n",
    "    )\n",
    "    basename = op.basename(filepath).lower()\n",
    "    for k, v in scan_type_map.items():\n",
    "        if k in basename:\n",
    "            return v\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def date_diff(date1, date2, abs=False):\n",
    "    \"\"\"Return date2 - date1 in days.\"\"\"\n",
    "    try:\n",
    "        diff = (date2 - date1).days\n",
    "        if abs:\n",
    "            return np.abs(diff)\n",
    "        else:\n",
    "            return diff\n",
    "    except TypeError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def find_closest_mri(\n",
    "    subj, scan_date, freesurfer_dir, limit_days=365, strict_limit=False\n",
    "):\n",
    "    \"\"\"Return closest MRI date, days from PET, and Freesurfer path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subj : str\n",
    "        The subject ID.\n",
    "    scan_date : str\n",
    "        Scan date (YYYY-MM-DD) to match the closest MRI scan to.\n",
    "    freesurfer_dir : str\n",
    "        Path to the top-level freesurfer directory containing individual\n",
    "        processed MRI directories like <subj>_<scan_date>.\n",
    "    limit_days : int\n",
    "        A warning is raised if no MRI scan is found within limit days\n",
    "        and np.nan is returned.\n",
    "    strict_limit : bool\n",
    "        If True, np.nan is returned if no MRI scan is found within limit days.\n",
    "    \"\"\"\n",
    "    proc_mris = glob(op.join(freesurfer_dir, f\"{subj}_*\"))\n",
    "    if len(proc_mris) == 0:\n",
    "        print(\n",
    "            f\"WARNING: {subj} scan on {scan_date} has no processed MRI scans in {freesurfer_dir}\"\n",
    "        )\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    proc_mri_dates = [check_dt_fmt(op.basename(p).split(\"_\")[1]) for p in proc_mris]\n",
    "\n",
    "    days_to_scan = []\n",
    "    for d in proc_mri_dates:\n",
    "        days_to_scan.append(\n",
    "            date_diff(datestr_to_datetime(d), datestr_to_datetime(scan_date), abs=True)\n",
    "        )\n",
    "    closest_mri = proc_mris[np.argmin(days_to_scan)]\n",
    "    closest_mri_date = proc_mri_dates[np.argmin(days_to_scan)]\n",
    "    min_days = min(days_to_scan)\n",
    "\n",
    "    if min_days > limit_days:\n",
    "        print(\n",
    "            f\"WARNING: {subj} scan on {scan_date} has no matching MRI within {limit_days} days\"\n",
    "        )\n",
    "        if strict_limit:\n",
    "            return np.nan, np.nan, np.nan\n",
    "\n",
    "    return closest_mri_date, min_days, closest_mri\n",
    "\n",
    "\n",
    "def now():\n",
    "    \"\"\"Return the current date and time down to seconds.\"\"\"\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "\n",
    "def glob_sort_mtime(pattern):\n",
    "    \"\"\"Return files matching pattern in most recent modified order.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    files : list of str\n",
    "        List of files matching pattern, sorted by most recent modified\n",
    "        (files[0] is the most recently modified).\n",
    "    \"\"\"\n",
    "    files = sorted(glob(pattern), key=op.getmtime, reverse=True)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_scans: (2067, 12)\n"
     ]
    }
   ],
   "source": [
    "# Load the most recent raw_scans df\n",
    "raw_scans = pd.read_csv(\n",
    "    glob_sort_mtime(op.join(PATHS[\"metadata\"], \"log\", f\"raw_pet_scans_*.csv\"))[0]\n",
    ")\n",
    "raw_scans = raw_scans.dropna().reset_index(drop=True)\n",
    "\n",
    "print(f\"raw_scans: {raw_scans.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/coredata/processing/leads/data/raw/fbb',\n",
       " '/mnt/coredata/processing/leads/data/raw/fdg',\n",
       " '/mnt/coredata/processing/leads/data/raw/ftp']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_raw_dirs = [\n",
    "    d\n",
    "    for d in glob(op.join(PATHS[\"raw\"], \"*\"))\n",
    "    if (op.isdir(d) and not (d.split(op.sep)[-1] == \"mri\"))\n",
    "]\n",
    "search_raw_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2069 scans from 619 subjects in /mnt/coredata/processing/leads/data/raw\n",
      "WARNING: LDS9410459 scan on 2024-03-05 has no matching MRI within 365 days\n",
      "WARNING: LDS0220071 scan on 2022-08-09 has no matching MRI within 365 days\n",
      "WARNING: LDS0370038 scan on 2023-01-05 has no matching MRI within 365 days\n",
      "WARNING: LDS0350171 scan on 2023-11-01 has no matching MRI within 365 days\n",
      "WARNING: LDS9410323 scan on 2020-12-10 has no processed MRI scans in /mnt/coredata/processing/leads/data/freesurfer\n",
      "WARNING: LDS0350342 scan on 2022-08-31 has no matching MRI within 365 days\n",
      "WARNING: LDS0370015 scan on 2022-05-10 has no matching MRI within 365 days\n",
      "WARNING: LDS0370316 scan on 2024-02-15 has no matching MRI within 365 days\n",
      "WARNING: LDS0350171 scan on 2023-11-30 has no matching MRI within 365 days\n",
      "WARNING: LDS0370449 scan on 2024-03-11 has no matching MRI within 365 days\n",
      "WARNING: LDS0220071 scan on 2022-10-18 has no matching MRI within 365 days\n",
      "WARNING: LDS0730083 scan on 2021-01-19 has no matching MRI within 365 days\n",
      "WARNING: LDS9410323 scan on 2021-01-07 has no processed MRI scans in /mnt/coredata/processing/leads/data/freesurfer\n",
      "WARNING: LDS0350342 scan on 2022-09-21 has no matching MRI within 365 days\n",
      "raw_scans: (2069, 7)\n"
     ]
    }
   ],
   "source": [
    "# Scrape the raw directory for all PET niftis\n",
    "raw_scans = scrape_raw(PATHS[\"raw\"])\n",
    "\n",
    "# Get paths for the raw nifti files copied into the processed directory\n",
    "# raw_cp_str = op.join(\n",
    "#     PATHS[\"processed\"],\n",
    "#     \"{subj}\",\n",
    "#     \"{scan_type}_{scan_date}\",\n",
    "#     \"{subj}_{scan_type}_{scan_date}.nii\",\n",
    "# )\n",
    "\n",
    "# Search processed Freesurfer dirs for closest MRI to each PET scan\n",
    "raw_scans[\"mri_date\"], raw_scans[\"days_to_mri\"], raw_scans[\"fs_dir\"] = zip(\n",
    "    *raw_scans.apply(\n",
    "        lambda x: find_closest_mri(x[\"subj\"], x[\"scan_date\"], PATHS[\"freesurfer\"]),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"raw_scans: {raw_scans.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/coredata/Projects/LEADS/data_f7p1/freesurfer_processing/LDS0370001_MRI_T1_2020-10-14'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = op.join(\n",
    "    \"/mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0370001/Timepoint2/MRI_T1_2020-10-14\",\n",
    "    \"LDS0370001_MRI_T1_2020-10-14_nu.nii\",\n",
    ")\n",
    "op.islink(fname)\n",
    "freesurfer_scan_dir = op.dirname(op.dirname(op.abspath(os.readlink(fname))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add processed MRI directories to raw_scans\n",
    "# proc_dir_old = \"/mnt/coredata/Projects/LEADS/data_f7p1/processed\"\n",
    "# mri_dirs = []\n",
    "# proc_mri_dirs_old = []\n",
    "# freesurfer_dirs_old = []\n",
    "# for idx, scan in raw_scans.iterrows():\n",
    "#     if scan[\"fs_dir\"] is np.nan:\n",
    "#         mri_dirs.append(np.nan)\n",
    "#         continue\n",
    "\n",
    "#     subj = scan[\"subj\"]\n",
    "#     mri_date = scan[\"fs_dir\"].split(\"_\")[1]\n",
    "#     proc_mri_dir_new = op.join(PATHS[\"processed\"], subj, f\"MRI-T1_{mri_date}\")\n",
    "\n",
    "#     # Find the old processed MRI and FreeSurfer directories\n",
    "#     max_tp = 6\n",
    "#     for tp in range(1, max_tp + 1):\n",
    "#         proc_mri_dir_old = op.join(\n",
    "#             proc_dir_old, subj, f\"Timepoint{tp}\", f\"MRI_T1_{mri_date}\"\n",
    "#         )\n",
    "#         if op.isdir(proc_mri_dir_old):\n",
    "#             os.makedirs(op.dirname(proc_mri_dir_new), exist_ok=True)\n",
    "#             # if not op.exists(proc_mri_dir_new):\n",
    "#             #     os.symlink(proc_mri_dir_old, proc_mri_dir_new)\n",
    "#             if op.islink(proc_mri_dir_new):\n",
    "#                 os.unlink(proc_mri_dir_new)\n",
    "#             os.makedirs(proc_mri_dir_new, exist_ok=True)\n",
    "#             proc_mri_dirs_old.append(proc_mri_dir_old)\n",
    "\n",
    "#             # Find the FreeSurfer directory from the nu.nii symlink\n",
    "#             nu_old = op.join(proc_mri_dir_old, f\"{subj}_MRI_T1_{mri_date}_nu.nii\")\n",
    "#             if op.islink(nu_old):\n",
    "#                 freesurfer_dir_old = op.dirname(\n",
    "#                     op.dirname(op.abspath(os.readlink(fname)))\n",
    "#                 )\n",
    "#                 freesurfer_dir_new = op.join(proc_mri_dir_new, \"freesurfer_7p1\")\n",
    "#                 freesurfer_link_new = op.join(proc_mri_dir_new, \"freesurfer\")\n",
    "#                 shutil.copytree(freesurfer_scan_dir, proc_mri_dir_new)\n",
    "#             break\n",
    "#         if tp == max_tp:\n",
    "#             proc_mri_dir_old = np.nan\n",
    "\n",
    "#     # Add the processed MRI directory to raw_scans[\"mri_dir\"]\n",
    "#     if op.exists(proc_mri_dir_new):\n",
    "#         mri_dirs.append(proc_mri_dir_new)\n",
    "#     else:\n",
    "#         mri_dirs.append(np.nan)\n",
    "\n",
    "# raw_scans[\"mri_dir\"] = mri_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_scans: (2067, 9)\n"
     ]
    }
   ],
   "source": [
    "# Drop raw_scans rows with missing data, then sort rows.\n",
    "raw_scans = (\n",
    "    raw_scans.dropna()\n",
    "    .sort_values([\"subj\", \"scan_type\", \"scan_date\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Convert days_to_mri to int\n",
    "raw_scans[\"days_to_mri\"] = raw_scans[\"days_to_mri\"].astype(int)\n",
    "\n",
    "# Add a visit column to raw_scans, with visit 1 being the earliest date\n",
    "# for a given subject and scan_type, visit 2 being the next earliest\n",
    "# date, and so on.\n",
    "raw_scans[\"visit\"] = raw_scans.groupby([\"subj\", \"scan_type\"]).cumcount() + 1\n",
    "cols = raw_scans.columns.tolist()\n",
    "cols.insert(cols.index(\"scan_type\") + 1, cols.pop(cols.index(\"visit\")))\n",
    "raw_scans = raw_scans[cols]\n",
    "\n",
    "print(f\"raw_scans: {raw_scans.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a diagnosis column to raw_scans\n",
    "dxf = op.join(PATHS[\"metadata\"], \"ssheets\", \"LEADS_Internal_PET-Screening.xlsx\")\n",
    "if op.isfile(dxf):\n",
    "    dx = pd.read_excel(dxf)\n",
    "    dx_map = {\"ID\": \"subj\", \"Cohort\": \"dx\"}\n",
    "    dx = dx.rename(columns=dx_map)[[\"subj\", \"dx\"]]\n",
    "    raw_scans = dx.merge(raw_scans, on=\"subj\", how=\"right\")\n",
    "\n",
    "# Add controls.\n",
    "subj_regf = op.join(\n",
    "    PATHS[\"metadata\"], \"ssheets\", \"Participant Registration_vertical.csv\"\n",
    ")\n",
    "if op.isfile(subj_regf):\n",
    "    subj_reg = pd.read_csv(subj_regf)\n",
    "    subj_reg_map = {\"subject.label\": \"subj\", \"dd_revision_field.translated_value\": \"dx\"}\n",
    "    subj_reg = subj_reg.rename(columns=subj_reg_map)[[\"subj\", \"dx\"]]\n",
    "cn_subjs = subj_reg.query(\"(dx=='Cognitively Normal Participant')\")[\"subj\"].tolist()\n",
    "raw_scans.loc[pd.isna(raw_scans[\"dx\"]), \"dx\"] = raw_scans.loc[\n",
    "    pd.isna(raw_scans[\"dx\"]), \"subj\"\n",
    "].apply(lambda x: \"CN\" if np.isin(x, cn_subjs) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find PET scans that are ready and needing to be processed\n",
    "proc_pet_dirs = []\n",
    "need_to_process = []\n",
    "for idx, scan in raw_scans.iterrows():\n",
    "    if scan[\"mri_dir\"] is np.nan:\n",
    "        proc_pet_dirs.append(np.nan)\n",
    "        need_to_process.append(False)\n",
    "        continue\n",
    "\n",
    "    proc_pet_dir = op.join(\n",
    "        PATHS[\"processed\"], scan[\"subj\"], f\"{scan['scan_type']}_{scan['scan_date']}\"\n",
    "    )\n",
    "    proc_pet_dirs.append(proc_pet_dir)\n",
    "    need_to_process.append(not op.exists(proc_pet_dir))\n",
    "\n",
    "raw_scans[\"proc_pet_dir\"] = proc_pet_dirs\n",
    "raw_scans[\"need_to_process\"] = need_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved raw_scans to /mnt/coredata/processing/leads/metadata/log/raw_pet_scans_2024-04-22-19-12-02.csv\n"
     ]
    }
   ],
   "source": [
    "# Save raw_scans to a CSV file\n",
    "outf = op.join(PATHS[\"metadata\"], \"log\", f\"raw_pet_scans_{now()}.csv\")\n",
    "raw_scans.to_csv(outf, index=False)\n",
    "print(f\"Saved raw_scans to {outf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy MRI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_freesurfer(scan, rm_existing=False):\n",
    "    \"\"\"Copy FreeSurfer directory to the processed MRI directory.\"\"\"\n",
    "    # Add processed MRI directories to raw_scans\n",
    "    fs_dir_old = \"/mnt/coredata/Projects/LEADS/data_f7p1/freesurfer_processing\"\n",
    "\n",
    "    # Create the processed MRI directory, if it doesn't already exist\n",
    "    if op.islink(scan[\"mri_dir\"]):\n",
    "        os.unlink(scan[\"mri_dir\"])\n",
    "    os.makedirs(scan[\"mri_dir\"], exist_ok=True)\n",
    "\n",
    "    # Copy the FreeSurfer directory to the processed MRI directory\n",
    "    fs_scan_dir_old = op.join(fs_dir_old, f\"{scan['subj']}_MRI_T1_{scan['mri_date']}\")\n",
    "    fs_scan_dir_new = op.join(scan[\"mri_dir\"], f\"freesurfer_7p1\")\n",
    "    fs_scan_link_new = fs_scan_dir_new.replace(\"freesurfer_7p1\", \"freesurfer\")\n",
    "    if op.isdir(fs_scan_dir_old):\n",
    "        if op.isdir(fs_scan_dir_new) and rm_existing:\n",
    "            shutil.rmtree(fs_scan_dir_new)\n",
    "        if not op.isdir(fs_scan_dir_new):\n",
    "            # Find files in fs_scan_dir_old that are dirs\n",
    "            subfiles = [\n",
    "                f\n",
    "                for f in os.listdir(fs_scan_dir_old)\n",
    "                if not op.islink(op.join(fs_scan_dir_old, f))\n",
    "            ]\n",
    "            if len(subfiles) > 0:\n",
    "                os.makedirs(fs_scan_dir_new, exist_ok=True)\n",
    "                for f in subfiles:\n",
    "                    shutil.copytree(\n",
    "                        op.join(fs_scan_dir_old, f),\n",
    "                        op.join(fs_scan_dir_new, f),\n",
    "                        symlinks=True,\n",
    "                    )\n",
    "\n",
    "            # Add a symlink to the new freesurfer directory\n",
    "            if op.islink(fs_scan_link_new):\n",
    "                os.unlink(fs_scan_link_new)\n",
    "            os.symlink(fs_scan_dir_new, fs_scan_link_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying FreeSurfer directories for 1092 MRIs\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "max_workers = 16\n",
    "mris_to_copy = raw_scans.drop_duplicates([\"subj\", \"mri_date\"]).to_dict(orient=\"records\")\n",
    "print(f\"Copying FreeSurfer directories for {len(mris_to_copy)} MRIs\")\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    executor.map(copy_freesurfer, mris_to_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add processed MRI directories to raw_scans\n",
    "cp_freesurfer = True\n",
    "fs_dir_old = \"/mnt/coredata/Projects/LEADS/data_f7p1/freesurfer_processing\"\n",
    "for idx, scan in raw_scans.drop_duplicates([\"subj\", \"mri_date\"]).iterrows():\n",
    "    if scan[\"subj\"] != \"LDS0370008\":\n",
    "        continue\n",
    "\n",
    "    # Create the processed MRI directory, if it doesn't already exist\n",
    "    if op.islink(scan[\"mri_dir\"]):\n",
    "        os.unlink(scan[\"mri_dir\"])\n",
    "    os.makedirs(scan[\"mri_dir\"], exist_ok=True)\n",
    "\n",
    "    # Copy the FreeSurfer directory to the processed MRI directory\n",
    "    fs_scan_dir_old = op.join(fs_dir_old, f\"{scan['subj']}_MRI_T1_{scan['mri_date']}\")\n",
    "    fs_scan_dir_new = op.join(scan[\"mri_dir\"], f\"freesurfer_7p1\")\n",
    "    fs_scan_link_new = fs_scan_dir_new.replace(\"freesurfer_7p1\", \"freesurfer\")\n",
    "    if op.isdir(fs_scan_dir_old):\n",
    "        if cp_freesurfer and not op.isdir(fs_scan_dir_new):\n",
    "            # Find files in fs_scan_dir_old that are dirs\n",
    "            subfiles = [\n",
    "                f\n",
    "                for f in os.listdir(fs_scan_dir_old)\n",
    "                if not op.islink(op.join(fs_scan_dir_old, f))\n",
    "            ]\n",
    "            if len(subfiles) > 0:\n",
    "                os.makedirs(fs_scan_dir_new, exist_ok=True)\n",
    "                for f in subfiles:\n",
    "                    shutil.copytree(\n",
    "                        op.join(fs_scan_dir_old, f),\n",
    "                        op.join(fs_scan_dir_new, f),\n",
    "                        symlinks=True,\n",
    "                    )\n",
    "\n",
    "            # Add a symlink to the new freesurfer directory\n",
    "            if op.islink(fs_scan_link_new):\n",
    "                os.unlink(fs_scan_link_new)\n",
    "            os.symlink(fs_scan_dir_new, fs_scan_link_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidate dirs in raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/coredata/processing/leads/data/raw'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdirs = [\"fbb\", \"fdg\", \"ftp\", \"mri\"]\n",
    "# for d in subdirs:\n",
    "#     os.makedirs(op.join(PATHS[\"processed\"], d), exist_ok=True)\n",
    "PATHS[\"raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move raw scan directories from raw/<scan_type>/<subj> to raw/<subj>\n",
    "scan_type_dirs = [\n",
    "    op.join(PATHS[\"raw\"], f)\n",
    "    for f in os.listdir(PATHS[\"raw\"])\n",
    "    if op.isdir(op.join(PATHS[\"raw\"], f))\n",
    "]\n",
    "for scan_type_dir in scan_type_dirs:\n",
    "    subj_dirs_old = [\n",
    "        op.join(scan_type_dir, f)\n",
    "        for f in os.listdir(scan_type_dir)\n",
    "        if op.isdir(op.join(scan_type_dir, f))\n",
    "    ]\n",
    "    for subj_dir_old in subj_dirs_old:\n",
    "        subj_dir_new = op.join(PATHS[\"raw\"], op.basename(subj_dir_old))\n",
    "        subj_scan_dirs_old = [\n",
    "            op.join(subj_dir_old, f)\n",
    "            for f in os.listdir(subj_dir_old)\n",
    "            if op.isdir(op.join(subj_dir_old, f))\n",
    "        ]\n",
    "        # Make the new subject directory if it doesn't already exist\n",
    "        if subj_scan_dirs_old:\n",
    "            os.makedirs(subj_dir_new, exist_ok=True)\n",
    "        for subj_scan_dir_old in subj_scan_dirs_old:\n",
    "            # Move the scan directory to its new location\n",
    "            shutil.move(subj_scan_dir_old, subj_dir_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_newdata_to_raw(\n",
    "    newdata_dir, raw_dir, overwrite=False, cleanup=True, verbose=True\n",
    "):\n",
    "    \"\"\"Move scans from newdata to raw, keeping file hierarchies intact.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    newdata_dir : str\n",
    "        The directory containing the new scan data. Must format like:\n",
    "            <newdata_dir>/<subj>/<...>/<nifti_or_dicom_files>\n",
    "    raw_dir : str\n",
    "        The directory to move the new scan data to. Structure after\n",
    "        moving will be:\n",
    "            <raw_dir>/<subj>/<...>/<nifti_or_dicom_files>\n",
    "    overwrite : bool\n",
    "        If True, overwrite existing scan directories in raw_dir with\n",
    "        directories from newdata_dir. If False, skip existing\n",
    "        directories.\n",
    "    cleanup : bool\n",
    "        If True, remove all files and folders from newdata_dir after\n",
    "        moving everything eligible to be moved to raw_dir.\n",
    "    verbose : bool\n",
    "        If True, print messages about what is happening as the function\n",
    "        runs.\n",
    "    \"\"\"\n",
    "\n",
    "    def do_cleanup():\n",
    "        \"\"\"Remove all files and folders from newdata.\"\"\"\n",
    "        if verbose:\n",
    "            print(f\"  Cleaning up {newdata_dir}\")\n",
    "        for file in os.listdir(newdata_dir):\n",
    "            filepath = op.join(newdata_dir, file)\n",
    "            if op.isdir(filepath):\n",
    "                shutil.rmtree(filepath)\n",
    "            else:\n",
    "                os.remove(filepath)\n",
    "\n",
    "    # Ensure the base directory paths are absolute and normalized\n",
    "    newdata_dir = op.normpath(newdata_dir)\n",
    "    raw_dir = op.normpath(raw_dir)\n",
    "\n",
    "    # Find all nifti and dicom files in newdata\n",
    "    check_exts = (\".nii\", \".nii.gz\", \".IMA\", \".dcm\")\n",
    "    glob_files = []\n",
    "    for ext in check_exts:\n",
    "        glob_files.extend(glob(op.join(newdata_dir, f\"**/*{ext}\"), recursive=True))\n",
    "\n",
    "    if verbose:\n",
    "        title = \"Moving newdata to raw\"\n",
    "        print(title, \"-\" * len(title), sep=\"\\n\")\n",
    "    if len(glob_files) == 0:\n",
    "        if verbose:\n",
    "            print(f\"  No nifti or dicom files found in {newdata_dir}\")\n",
    "        do_cleanup()\n",
    "        return\n",
    "\n",
    "    # Find all unique nifti- or dicom-containing directories in newdata\n",
    "    source_dirs = set([op.dirname(f) for f in glob_files])\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"  Found {len(source_dirs)} nifti- or dicom-containing directories in {newdata_dir}\"\n",
    "        )\n",
    "\n",
    "    for source_dir in source_dirs:\n",
    "        # Create a matching file hierarchy in raw as in newdata\n",
    "        target_dir = op.join(raw_dir, op.relpath(source_dir, newdata_dir))\n",
    "\n",
    "        # Check if the target directory exists\n",
    "        if op.exists(target_dir):\n",
    "            # If overwrite is True, remove the existing directory\n",
    "            if overwrite:\n",
    "                if verbose:\n",
    "                    print(f\"  Overwriting existing raw directory: {target_dir}\")\n",
    "                shutil.rmtree(target_dir)\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"  Skipping existing raw directory: {target_dir}\")\n",
    "                continue\n",
    "\n",
    "        # Create the necessary directory structure, then copy source to\n",
    "        # target\n",
    "        os.makedirs(op.dirname(target_dir), exist_ok=True)\n",
    "        shutil.move(source_dir, target_dir)\n",
    "        if verbose:\n",
    "            print(f\"  Moved {source_dir} to {target_dir}\")\n",
    "\n",
    "    # Clean up empty directories in newdata\n",
    "    if cleanup:\n",
    "        do_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving newdata to raw\n",
      "---------------------\n",
      "  Found 7 nifti- or dicom-containing directories in /home/mac/dschonhaut/tmp/leads/restructuring/newdata\n",
      "  Skipping existing raw directory: /home/mac/dschonhaut/tmp/leads/restructuring/raw/b/aa\n",
      "  Skipping existing raw directory: /home/mac/dschonhaut/tmp/leads/restructuring/raw/a\n",
      "  Skipping existing raw directory: /home/mac/dschonhaut/tmp/leads/restructuring/raw/c/aa/aaa\n",
      "  Skipping existing raw directory: /home/mac/dschonhaut/tmp/leads/restructuring/raw/c/aa/aab\n",
      "  Skipping existing raw directory: /home/mac/dschonhaut/tmp/leads/restructuring/raw/b/ab\n",
      "  Skipping existing raw directory: /home/mac/dschonhaut/tmp/leads/restructuring/raw/c/ab/aab\n",
      "  Skipping existing raw directory: /home/mac/dschonhaut/tmp/leads/restructuring/raw/c/ab/aaa\n",
      "  Cleaning up /home/mac/dschonhaut/tmp/leads/restructuring/newdata\n"
     ]
    }
   ],
   "source": [
    "newdata_dir = \"/home/mac/dschonhaut/tmp/leads/restructuring/newdata\"\n",
    "raw_dir = \"/home/mac/dschonhaut/tmp/leads/restructuring/raw\"\n",
    "\n",
    "move_newdata_to_raw(\n",
    "    newdata_dir=newdata_dir,\n",
    "    raw_dir=raw_dir,\n",
    "    overwrite=False,\n",
    "    cleanup=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup PET directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import general.basic.helper_funcs as hf\n",
    "import general.basic.str_methods as strm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /mnt/coredata/processing/leads/metadata/log/raw_pet_scans_2024-03-27-22-54-15.csv\n",
      "raw_scans: (2065, 12)\n"
     ]
    }
   ],
   "source": [
    "raw_scansf = glob_sort_mtime(op.join(PATHS[\"metadata\"], \"log\", \"raw_pet_scans_*.csv\"))[\n",
    "    0\n",
    "]\n",
    "raw_scans = pd.read_csv(raw_scansf)\n",
    "\n",
    "# Remove rows with missing data\n",
    "raw_scans = raw_scans.dropna().reset_index(drop=True)\n",
    "raw_scans = raw_scans.drop(935).reset_index(drop=True)\n",
    "\n",
    "# Fix raw PET filepaths\n",
    "replace_vals = {\n",
    "    \"raw/fbb\": \"raw\",\n",
    "    \"raw/fdg\": \"raw\",\n",
    "    \"raw/ftp\": \"raw\",\n",
    "}\n",
    "raw_scans[\"raw_petf\"] = raw_scans[\"raw_petf\"].apply(\n",
    "    lambda x: strm.str_replace(x, replace_vals)\n",
    ")\n",
    "\n",
    "print(f\"reading {raw_scansf}\")\n",
    "print(f\"raw_scans: {raw_scans.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix raw PET filepaths\n",
    "replace_vals = {\n",
    "    \"raw/fbb\": \"raw\",\n",
    "    \"raw/fdg\": \"raw\",\n",
    "    \"raw/ftp\": \"raw\",\n",
    "}\n",
    "raw_scans[\"raw_petf\"] = raw_scans[\"raw_petf\"].apply(\n",
    "    lambda x: strm.str_replace(x, replace_vals)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all expected files and directories exist\n",
    "raw_scans[\"raw_petf_exists\"] = raw_scans[\"raw_petf\"].apply(lambda x: op.isfile(x))\n",
    "raw_scans[\"mri_dir_exists\"] = raw_scans[\"mri_dir\"].apply(lambda x: op.isdir(x))\n",
    "raw_scans[\"proc_pet_dir_exists\"] = raw_scans[\"proc_pet_dir\"].apply(\n",
    "    lambda x: op.isdir(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scans[\"scan_tag\"] = raw_scans.apply(\n",
    "    lambda x: \"_\".join([x[\"subj\"], x[\"scan_type\"], x[\"scan_date\"]]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj</th>\n",
       "      <th>dx</th>\n",
       "      <th>scan_date</th>\n",
       "      <th>scan_type</th>\n",
       "      <th>visit</th>\n",
       "      <th>raw_petf</th>\n",
       "      <th>mri_date</th>\n",
       "      <th>days_to_mri</th>\n",
       "      <th>fs_dir</th>\n",
       "      <th>mri_dir</th>\n",
       "      <th>proc_pet_dir</th>\n",
       "      <th>need_to_process</th>\n",
       "      <th>raw_petf_exists</th>\n",
       "      <th>mri_dir_exists</th>\n",
       "      <th>proc_pet_dir_exists</th>\n",
       "      <th>scan_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDS0070120</td>\n",
       "      <td>CN</td>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>FBB</td>\n",
       "      <td>1</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/raw/LDS007...</td>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>1</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/freesurfer...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>LDS0070120_FBB_2019-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDS0070120</td>\n",
       "      <td>CN</td>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>FDG</td>\n",
       "      <td>1</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/raw/LDS007...</td>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>1</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/freesurfer...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>LDS0070120_FDG_2021-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDS0070120</td>\n",
       "      <td>CN</td>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>FTP</td>\n",
       "      <td>1</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/raw/LDS007...</td>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>0</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/freesurfer...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>LDS0070120_FTP_2019-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDS0070166</td>\n",
       "      <td>EOAD</td>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>FBB</td>\n",
       "      <td>1</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/raw/LDS007...</td>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>0</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/freesurfer...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>LDS0070166_FBB_2019-08-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDS0070166</td>\n",
       "      <td>EOAD</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>FBB</td>\n",
       "      <td>2</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/raw/LDS007...</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>0</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/freesurfer...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>LDS0070166_FBB_2020-09-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subj    dx   scan_date scan_type  visit  \\\n",
       "0  LDS0070120    CN  2019-06-19       FBB      1   \n",
       "1  LDS0070120    CN  2021-07-14       FDG      1   \n",
       "2  LDS0070120    CN  2019-06-20       FTP      1   \n",
       "3  LDS0070166  EOAD  2019-08-22       FBB      1   \n",
       "4  LDS0070166  EOAD  2020-09-16       FBB      2   \n",
       "\n",
       "                                            raw_petf    mri_date  days_to_mri  \\\n",
       "0  /mnt/coredata/processing/leads/data/raw/LDS007...  2019-06-20            1   \n",
       "1  /mnt/coredata/processing/leads/data/raw/LDS007...  2021-07-13            1   \n",
       "2  /mnt/coredata/processing/leads/data/raw/LDS007...  2019-06-20            0   \n",
       "3  /mnt/coredata/processing/leads/data/raw/LDS007...  2019-08-22            0   \n",
       "4  /mnt/coredata/processing/leads/data/raw/LDS007...  2020-09-16            0   \n",
       "\n",
       "                                              fs_dir  \\\n",
       "0  /mnt/coredata/processing/leads/data/freesurfer...   \n",
       "1  /mnt/coredata/processing/leads/data/freesurfer...   \n",
       "2  /mnt/coredata/processing/leads/data/freesurfer...   \n",
       "3  /mnt/coredata/processing/leads/data/freesurfer...   \n",
       "4  /mnt/coredata/processing/leads/data/freesurfer...   \n",
       "\n",
       "                                             mri_dir  \\\n",
       "0  /mnt/coredata/processing/leads/data/processed/...   \n",
       "1  /mnt/coredata/processing/leads/data/processed/...   \n",
       "2  /mnt/coredata/processing/leads/data/processed/...   \n",
       "3  /mnt/coredata/processing/leads/data/processed/...   \n",
       "4  /mnt/coredata/processing/leads/data/processed/...   \n",
       "\n",
       "                                        proc_pet_dir  need_to_process  \\\n",
       "0  /mnt/coredata/processing/leads/data/processed/...             True   \n",
       "1  /mnt/coredata/processing/leads/data/processed/...             True   \n",
       "2  /mnt/coredata/processing/leads/data/processed/...             True   \n",
       "3  /mnt/coredata/processing/leads/data/processed/...             True   \n",
       "4  /mnt/coredata/processing/leads/data/processed/...             True   \n",
       "\n",
       "   raw_petf_exists  mri_dir_exists  proc_pet_dir_exists  \\\n",
       "0             True            True                False   \n",
       "1             True            True                False   \n",
       "2             True            True                False   \n",
       "3             True            True                False   \n",
       "4             True            True                False   \n",
       "\n",
       "                    scan_tag  \n",
       "0  LDS0070120_FBB_2019-06-19  \n",
       "1  LDS0070120_FDG_2021-07-14  \n",
       "2  LDS0070120_FTP_2019-06-20  \n",
       "3  LDS0070166_FBB_2019-08-22  \n",
       "4  LDS0070166_FBB_2020-09-16  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2064, 16), (2064, 16))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scans.shape, raw_scans.query(\"(need_to_process==True)\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import shutil\n",
    "\n",
    "\n",
    "def setup_pet_proc_dirs(raw_scans=None, overwrite=False, verbose=True):\n",
    "    \"\"\"Create processed PET directories and link to associated MRIs.\n",
    "\n",
    "    For each scan that needs to be processed, there must already be:\n",
    "    1. A raw PET file in .nii format\n",
    "    2. A processed MRI directory that will be linked to\n",
    "\n",
    "    This function then does the following for each scan:\n",
    "    1. Creates new processed PET directory\n",
    "    2. Copies raw PET file to processed PET directory and renames it\n",
    "    3. Creates symbolic link from processed PET directory to the\n",
    "       associated MRI directory\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_scans : DataFrame\n",
    "        A pandas DataFrame with columns 'raw_petf', 'scan_tag',\n",
    "        'mri_dir', and 'proc_pet_dir', which hold paths to raw PET .nii\n",
    "        files, scan tags (\"<subj>_<tracer>_<scan_date>\"), processed MRI\n",
    "        directories that will be used to process each PET scan, and\n",
    "        target directories for processed PET data that will be created\n",
    "        by this function, respectively.\n",
    "    overwrite : bool, optional\n",
    "        If True, overwrite existing processed PET directories if they\n",
    "        exist. If False, skip scans with existing processed PET\n",
    "        directories.\n",
    "    verbose : bool, optional\n",
    "        If True, output status messages during execution.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Print the welcome message\n",
    "    if verbose:\n",
    "        title = f\"\\nCreating processed PET directories\"\n",
    "        print(title, \"-\" * len(title), sep=\"\\n\")\n",
    "\n",
    "    # Load the most recently saved raw_scans spreadsheet if not provided\n",
    "    if raw_scans is None:\n",
    "        raw_scansf = glob_sort_mtime(\n",
    "            op.join(PATHS[\"metadata\"], \"log\", \"raw_pet_scans_*.csv\")\n",
    "        )[0]\n",
    "        if verbose:\n",
    "            print(f\"  Reading {raw_scansf}\")\n",
    "        raw_scans = pd.read_csv(raw_scansf)\n",
    "\n",
    "    # Filter scans that need to be processed\n",
    "    raw_scans = raw_scans.query(\"(need_to_process==True)\").reset_index(drop=True)\n",
    "    if verbose:\n",
    "        print(f\"  {raw_scans.shape[0]} scans to process\")\n",
    "\n",
    "    # Loop over each scan and do directory setup\n",
    "    for idx, scan in raw_scans.iterrows():\n",
    "        # Make sure the raw PET file exists\n",
    "        if not op.isfile(scan[\"raw_petf\"]):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"  Skipping {scan['scan_tag']} due to missing raw PET file: {scan['raw_petf']}\"\n",
    "                )\n",
    "            continue\n",
    "        elif not scan[\"raw_petf\"].endswith(\".nii\"):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"  Skipping {scan['scan_tag']} as raw PET file does not end in .nii: {scan['raw_petf']}\"\n",
    "                )\n",
    "            continue\n",
    "        # Make sure the MRI directory exists\n",
    "        if not op.isdir(scan[\"mri_dir\"]):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"  Skipping {scan['scan_tag']} due to missing MRI directory: {scan['mri_dir']}\"\n",
    "                )\n",
    "            continue\n",
    "        # Remove existing processed PET directories if overwrite is True\n",
    "        if op.isdir(scan[\"proc_pet_dir\"]):\n",
    "            if overwrite:\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        f\"  Removing existing directory and its contents: {scan['proc_pet_dir']}\"\n",
    "                    )\n",
    "                shutil.rmtree(scan[\"proc_pet_dir\"])\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        f\"  Skipping {scan['scan_tag']} due to existing processed PET directory: {scan['proc_pet_dir']}\"\n",
    "                    )\n",
    "                continue\n",
    "\n",
    "        # Create the processed PET directory\n",
    "        os.makedirs(scan[\"proc_pet_dir\"])\n",
    "\n",
    "        # Copy the raw PET file to the processed PET directory\n",
    "        infile = scan[\"raw_petf\"]\n",
    "        outfile = op.join(scan[\"proc_pet_dir\"], f\"{scan['scan_tag']}.nii\")\n",
    "        shutil.copy(infile, outfile)\n",
    "\n",
    "        # Create a symlink to the processed MRI directory\n",
    "        link_src = scan[\"mri_dir\"]\n",
    "        link_dst = op.join(scan[\"proc_pet_dir\"], \"mri\")\n",
    "        os.symlink(link_src, link_dst)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>raw_petf_exists</th>\n",
       "      <th>mri_dir_exists</th>\n",
       "      <th>proc_pet_dir_exists</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scan_type</th>\n",
       "      <th>visit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">FBB</th>\n",
       "      <th>1</th>\n",
       "      <td>614/614 (100.0%)</td>\n",
       "      <td>614/614 (100.0%)</td>\n",
       "      <td>0/614 (0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238/238 (100.0%)</td>\n",
       "      <td>238/238 (100.0%)</td>\n",
       "      <td>0/238 (0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94/94 (100.0%)</td>\n",
       "      <td>94/94 (100.0%)</td>\n",
       "      <td>0/94 (0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26/26 (100.0%)</td>\n",
       "      <td>26/26 (100.0%)</td>\n",
       "      <td>0/26 (0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDG</th>\n",
       "      <th>1</th>\n",
       "      <td>156/156 (100.0%)</td>\n",
       "      <td>156/156 (100.0%)</td>\n",
       "      <td>0/156 (0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">FTP</th>\n",
       "      <th>1</th>\n",
       "      <td>604/604 (100.0%)</td>\n",
       "      <td>604/604 (100.0%)</td>\n",
       "      <td>0/604 (0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219/219 (100.0%)</td>\n",
       "      <td>219/219 (100.0%)</td>\n",
       "      <td>0/219 (0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84/84 (100.0%)</td>\n",
       "      <td>84/84 (100.0%)</td>\n",
       "      <td>0/84 (0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29/29 (100.0%)</td>\n",
       "      <td>29/29 (100.0%)</td>\n",
       "      <td>0/29 (0.0%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  raw_petf_exists    mri_dir_exists proc_pet_dir_exists\n",
       "scan_type visit                                                        \n",
       "FBB       1      614/614 (100.0%)  614/614 (100.0%)        0/614 (0.0%)\n",
       "          2      238/238 (100.0%)  238/238 (100.0%)        0/238 (0.0%)\n",
       "          3        94/94 (100.0%)    94/94 (100.0%)         0/94 (0.0%)\n",
       "          4        26/26 (100.0%)    26/26 (100.0%)         0/26 (0.0%)\n",
       "FDG       1      156/156 (100.0%)  156/156 (100.0%)        0/156 (0.0%)\n",
       "FTP       1      604/604 (100.0%)  604/604 (100.0%)        0/604 (0.0%)\n",
       "          2      219/219 (100.0%)  219/219 (100.0%)        0/219 (0.0%)\n",
       "          3        84/84 (100.0%)    84/84 (100.0%)         0/84 (0.0%)\n",
       "          4        29/29 (100.0%)    29/29 (100.0%)         0/29 (0.0%)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scans.groupby([\"scan_type\", \"visit\"]).agg(\n",
    "    {\n",
    "        \"raw_petf_exists\": hf.count_pct,\n",
    "        \"mri_dir_exists\": hf.count_pct,\n",
    "        \"proc_pet_dir_exists\": hf.count_pct,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "need_to_process  scan_type  visit\n",
       "True             FBB        1        614\n",
       "                            2        238\n",
       "                            3         94\n",
       "                            4         26\n",
       "                 FDG        1        156\n",
       "                 FTP        1        604\n",
       "                            2        219\n",
       "                            3         84\n",
       "                            4         29\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scans.groupby([\"need_to_process\", \"scan_type\", \"visit\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/coredata/processing/leads/data/processed/LDS0070120/FBB_2019-06-19'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scans.iloc[0][\"proc_pet_dir\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: LDS0730083 FTP scan on 2021-01-19 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0730083/Timepoint*/FTP_2021-01-19\n",
      "WARNING: LDS0730150 FTP scan on 2021-11-10 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0730150/Timepoint*/FTP_2021-11-10\n",
      "WARNING: LDS0730150 FBB scan on 2021-12-09 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0730150/Timepoint*/FBB_2021-12-09\n",
      "WARNING: LDS0370015 FBB scan on 2022-05-10 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0370015/Timepoint*/FBB_2022-05-10\n",
      "WARNING: LDS9410395 FDG scan on 2022-08-03 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS9410395/Timepoint*/FDG_2022-08-03\n",
      "WARNING: LDS0220071 FBB scan on 2022-08-09 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0220071/Timepoint*/FBB_2022-08-09\n",
      "WARNING: LDS0350342 FBB scan on 2022-08-31 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0350342/Timepoint*/FBB_2022-08-31\n",
      "WARNING: LDS0350342 FTP scan on 2022-09-21 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0350342/Timepoint*/FTP_2022-09-21\n",
      "WARNING: LDS0070313 FBB scan on 2022-10-12 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0070313/Timepoint*/FBB_2022-10-12\n",
      "WARNING: LDS0070313 FTP scan on 2022-10-13 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0070313/Timepoint*/FTP_2022-10-13\n",
      "WARNING: LDS0220071 FTP scan on 2022-10-18 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0220071/Timepoint*/FTP_2022-10-18\n",
      "WARNING: LDS0370038 FBB scan on 2023-01-05 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0370038/Timepoint*/FBB_2023-01-05\n",
      "WARNING: LDS0820514 FTP scan on 2023-03-06 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0820514/Timepoint*/FTP_2023-03-06\n",
      "WARNING: LDS0350171 FBB scan on 2023-11-01 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0350171/Timepoint*/FBB_2023-11-01\n",
      "WARNING: LDS0350171 FTP scan on 2023-11-30 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0350171/Timepoint*/FTP_2023-11-30\n",
      "WARNING: LDS9410287 FTP scan on 2024-01-31 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS9410287/Timepoint*/FTP_2024-01-31\n",
      "WARNING: LDS3600455 FTP scan on 2024-02-02 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS3600455/Timepoint*/FTP_2024-02-02\n",
      "WARNING: LDS3600455 FBB scan on 2024-02-06 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS3600455/Timepoint*/FBB_2024-02-06\n",
      "WARNING: LDS0370316 FBB scan on 2024-02-15 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0370316/Timepoint*/FBB_2024-02-15\n",
      "WARNING: LDS9410572 FBB scan on 2024-02-20 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS9410572/Timepoint*/FBB_2024-02-20\n",
      "WARNING: LDS1770264 FBB scan on 2024-02-22 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS1770264/Timepoint*/FBB_2024-02-22\n",
      "WARNING: LDS0220273 FTP scan on 2024-02-22 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0220273/Timepoint*/FTP_2024-02-22\n",
      "WARNING: LDS3600571 FTP scan on 2024-03-01 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS3600571/Timepoint*/FTP_2024-03-01\n",
      "WARNING: LDS9410459 FBB scan on 2024-03-05 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS9410459/Timepoint*/FBB_2024-03-05\n",
      "WARNING: LDS3600421 FTP scan on 2024-03-05 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS3600421/Timepoint*/FTP_2024-03-05\n",
      "WARNING: LDS3600542 FBB scan on 2024-03-05 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS3600542/Timepoint*/FBB_2024-03-05\n",
      "WARNING: LDS3600571 FBB scan on 2024-03-07 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS3600571/Timepoint*/FBB_2024-03-07\n",
      "WARNING: LDS0370449 FTP scan on 2024-03-11 is missing a processed PET dir in /mnt/coredata/Projects/LEADS/data_f7p1/processed/LDS0370449/Timepoint*/FTP_2024-03-11\n"
     ]
    }
   ],
   "source": [
    "file_renaming_map = {\n",
    "    \"FBB\": {\n",
    "        op.join(pet_dir_old, \"compwm_ref_mask.nii\"): op.join(mri_dir, \"\"),\n",
    "        op.join(pet_dir_old, \"\"): op.join(mri_dir, \"\"),\n",
    "        op.join(pet_dir_old, \"\"): op.join(mri_dir, \"\"),\n",
    "        op.join(pet_dir_old, \"\"): op.join(mri_dir, \"\"),\n",
    "        op.join(pet_dir_old, \"\"): op.join(mri_dir, \"\"),\n",
    "        op.join(pet_dir_old, \"\"): op.join(mri_dir, \"\"),\n",
    "    },\n",
    "    \"FTP\": {\n",
    "        op.join(pet_dir_old, \"\"): op.join(mri_dir, \"\"),\n",
    "        op.join(pet_dir_old, \"\"): op.join(mri_dir, \"\"),\n",
    "    },\n",
    "    \"MRI-T1\": {},\n",
    "}\n",
    "\n",
    "# copy mask files from PET to MRI proc dirs\n",
    "for idx, scan in (\n",
    "    raw_scans.query(\"(scan_type==['FBB','FTP'])\").sort_values(\"scan_date\").iterrows()\n",
    "):\n",
    "    try:\n",
    "        globstr = f\"/mnt/coredata/Projects/LEADS/data_f7p1/processed/{scan['subj']}/Timepoint*/{scan['scan_type']}_{scan['scan_date']}\"\n",
    "        pet_dir_old = glob(globstr)[0]\n",
    "    except IndexError:\n",
    "        print(\n",
    "            f\"WARNING: {scan['subj']} {scan['scan_type']} scan on {scan['scan_date']} is missing a processed PET dir in {globstr}\"\n",
    "        )\n",
    "        continue\n",
    "    try:\n",
    "        globstr = f\"/mnt/coredata/Projects/LEADS/data_f7p1/processed/{scan['subj']}/Timepoint*/MRI_T1_{scan['mri_date']}\"\n",
    "        mri_dir_old = glob(globstr)[0]\n",
    "    except IndexError:\n",
    "        print(\n",
    "            f\"WARNING: {scan['subj']} MRI scan on {scan['scan_date']} is missing a processed MRI dir in {globstr}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # copy mask files from PET to MRI proc dirs\n",
    "    mri_dir = scan[\"mri_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj</th>\n",
       "      <th>dx</th>\n",
       "      <th>scan_date</th>\n",
       "      <th>scan_type</th>\n",
       "      <th>visit</th>\n",
       "      <th>raw_petf</th>\n",
       "      <th>mri_date</th>\n",
       "      <th>days_to_mri</th>\n",
       "      <th>fs_dir</th>\n",
       "      <th>mri_dir</th>\n",
       "      <th>proc_pet_dir</th>\n",
       "      <th>need_to_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>LDS0370008</td>\n",
       "      <td>EOAD</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>FBB</td>\n",
       "      <td>1</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/raw/fbb/LD...</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>0</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/freesurfer...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>LDS0370008</td>\n",
       "      <td>EOAD</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>FBB</td>\n",
       "      <td>2</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/raw/fbb/LD...</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>0</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/freesurfer...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>LDS0370008</td>\n",
       "      <td>EOAD</td>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>FBB</td>\n",
       "      <td>3</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/raw/fbb/LD...</td>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>1</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/freesurfer...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>LDS0370008</td>\n",
       "      <td>EOAD</td>\n",
       "      <td>2021-11-16</td>\n",
       "      <td>FBB</td>\n",
       "      <td>4</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/raw/fbb/LD...</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>13</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/freesurfer...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>LDS0370008</td>\n",
       "      <td>EOAD</td>\n",
       "      <td>2018-08-27</td>\n",
       "      <td>FTP</td>\n",
       "      <td>1</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/raw/ftp/LD...</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>12</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/freesurfer...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>LDS0370008</td>\n",
       "      <td>EOAD</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>FTP</td>\n",
       "      <td>2</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/raw/ftp/LD...</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>14</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/freesurfer...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>LDS0370008</td>\n",
       "      <td>EOAD</td>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>FTP</td>\n",
       "      <td>3</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/raw/ftp/LD...</td>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>0</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/freesurfer...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>LDS0370008</td>\n",
       "      <td>EOAD</td>\n",
       "      <td>2021-12-09</td>\n",
       "      <td>FTP</td>\n",
       "      <td>4</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/raw/ftp/LD...</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>36</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/freesurfer...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>/mnt/coredata/processing/leads/data/processed/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           subj    dx   scan_date scan_type  visit  \\\n",
       "680  LDS0370008  EOAD  2018-08-15       FBB      1   \n",
       "681  LDS0370008  EOAD  2019-09-19       FBB      2   \n",
       "682  LDS0370008  EOAD  2020-10-28       FBB      3   \n",
       "683  LDS0370008  EOAD  2021-11-16       FBB      4   \n",
       "684  LDS0370008  EOAD  2018-08-27       FTP      1   \n",
       "685  LDS0370008  EOAD  2019-10-03       FTP      2   \n",
       "686  LDS0370008  EOAD  2020-10-29       FTP      3   \n",
       "687  LDS0370008  EOAD  2021-12-09       FTP      4   \n",
       "\n",
       "                                              raw_petf    mri_date  \\\n",
       "680  /mnt/coredata/processing/leads/data/raw/fbb/LD...  2018-08-15   \n",
       "681  /mnt/coredata/processing/leads/data/raw/fbb/LD...  2019-09-19   \n",
       "682  /mnt/coredata/processing/leads/data/raw/fbb/LD...  2020-10-29   \n",
       "683  /mnt/coredata/processing/leads/data/raw/fbb/LD...  2021-11-03   \n",
       "684  /mnt/coredata/processing/leads/data/raw/ftp/LD...  2018-08-15   \n",
       "685  /mnt/coredata/processing/leads/data/raw/ftp/LD...  2019-09-19   \n",
       "686  /mnt/coredata/processing/leads/data/raw/ftp/LD...  2020-10-29   \n",
       "687  /mnt/coredata/processing/leads/data/raw/ftp/LD...  2021-11-03   \n",
       "\n",
       "     days_to_mri                                             fs_dir  \\\n",
       "680            0  /mnt/coredata/processing/leads/data/freesurfer...   \n",
       "681            0  /mnt/coredata/processing/leads/data/freesurfer...   \n",
       "682            1  /mnt/coredata/processing/leads/data/freesurfer...   \n",
       "683           13  /mnt/coredata/processing/leads/data/freesurfer...   \n",
       "684           12  /mnt/coredata/processing/leads/data/freesurfer...   \n",
       "685           14  /mnt/coredata/processing/leads/data/freesurfer...   \n",
       "686            0  /mnt/coredata/processing/leads/data/freesurfer...   \n",
       "687           36  /mnt/coredata/processing/leads/data/freesurfer...   \n",
       "\n",
       "                                               mri_dir  \\\n",
       "680  /mnt/coredata/processing/leads/data/processed/...   \n",
       "681  /mnt/coredata/processing/leads/data/processed/...   \n",
       "682  /mnt/coredata/processing/leads/data/processed/...   \n",
       "683  /mnt/coredata/processing/leads/data/processed/...   \n",
       "684  /mnt/coredata/processing/leads/data/processed/...   \n",
       "685  /mnt/coredata/processing/leads/data/processed/...   \n",
       "686  /mnt/coredata/processing/leads/data/processed/...   \n",
       "687  /mnt/coredata/processing/leads/data/processed/...   \n",
       "\n",
       "                                          proc_pet_dir  need_to_process  \n",
       "680  /mnt/coredata/processing/leads/data/processed/...             True  \n",
       "681  /mnt/coredata/processing/leads/data/processed/...             True  \n",
       "682  /mnt/coredata/processing/leads/data/processed/...             True  \n",
       "683  /mnt/coredata/processing/leads/data/processed/...             True  \n",
       "684  /mnt/coredata/processing/leads/data/processed/...             True  \n",
       "685  /mnt/coredata/processing/leads/data/processed/...             True  \n",
       "686  /mnt/coredata/processing/leads/data/processed/...             True  \n",
       "687  /mnt/coredata/processing/leads/data/processed/...             True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scans.query(\"(subj=='LDS0370008')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EOAD       396\n",
       "EOnonAD    122\n",
       "CN          99\n",
       "NaN          1\n",
       "Name: dx, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scans.drop_duplicates(\"subj\")[\"dx\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_scans: (2067, 12)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
