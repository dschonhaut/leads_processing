{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import os.path as op\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 999\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sys.path.append(op.join(op.expanduser(\"~\"), \"code\", \"style\"))\n",
    "from colors import get_colors\n",
    "\n",
    "co, palettes = get_colors()\n",
    "\n",
    "from general.basic.config import get_plot_defaults, set_rcparams\n",
    "\n",
    "mpl.rcParams = set_rcparams(mpl.rcParams)\n",
    "mpl.rcParams[\"axes.grid\"] = False\n",
    "d = get_plot_defaults()\n",
    "co = d.get(\"colors\", None)\n",
    "colws = d.get(\"colws\", None)\n",
    "font = d.get(\"font\", None)\n",
    "lws = d.get(\"lws\", None)\n",
    "pad = d.get(\"pad\", None)\n",
    "palettes = d.get(\"palettes\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and format data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed scan list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glob_sort_mtime(pattern):\n",
    "    \"\"\"Return files matching pattern in most recent modified order.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    files : list of str\n",
    "        List of files matching pattern, sorted by most recent modified\n",
    "        (files[0] is the most recently modified).\n",
    "    \"\"\"\n",
    "    files = sorted(glob(pattern), key=op.getmtime, reverse=True)\n",
    "    return files\n",
    "\n",
    "\n",
    "def frglob(topdir, base_starts=\"\", base_ends=\"\", base_contains=\"\", path_contains=\"\"):\n",
    "    \"\"\"Return a list of all files nested under topdir that meet criteria\n",
    "\n",
    "    A fast, recursive glob search.\n",
    "    \"\"\"\n",
    "\n",
    "    def _path_recurse(\n",
    "        path, base_starts=\"\", base_ends=\"\", base_contains=\"\", path_contains=\"\"\n",
    "    ):\n",
    "        with os.scandir(path) as entries:\n",
    "            for entry in entries:\n",
    "                if entry.is_dir():\n",
    "                    _path_recurse(\n",
    "                        entry.path, base_starts, base_ends, base_contains, path_contains\n",
    "                    )\n",
    "                elif entry.is_file():\n",
    "                    if base_starts:\n",
    "                        if not entry.name.startswith(base_starts):\n",
    "                            continue\n",
    "                    if base_ends:\n",
    "                        if not entry.name.endswith(base_ends):\n",
    "                            continue\n",
    "                    if base_contains:\n",
    "                        if base_contains not in entry.name:\n",
    "                            continue\n",
    "                    if path_contains:\n",
    "                        if path_contains not in op.relpath(\n",
    "                            op.dirname(entry.path), path\n",
    "                        ):\n",
    "                            continue\n",
    "                    outfiles.append(entry.path)\n",
    "\n",
    "    outfiles = []\n",
    "    _path_recurse(topdir, base_starts, base_ends, base_contains, path_contains)\n",
    "    return outfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define project paths\n",
    "proj_dir = \"/mnt/coredata/processing/leads\"\n",
    "code_dir = op.join(proj_dir, \"code\")\n",
    "data_dir = op.join(proj_dir, \"data\")\n",
    "metadata_dir = op.join(proj_dir, \"metadata\")\n",
    "\n",
    "extraction_dir = op.join(data_dir, \"extraction\")\n",
    "proc_dir = op.join(data_dir, \"processed\")\n",
    "\n",
    "atri_dir = op.join(metadata_dir, \"atri\")\n",
    "loni_dir = op.join(metadata_dir, \"loni\")\n",
    "scans_to_process_dir = op.join(metadata_dir, \"scans_to_process\")\n",
    "qc_dir = op.join(metadata_dir, \"qc\")\n",
    "\n",
    "qreport_dir = op.join(extraction_dir, \"quarterly_report_files\")\n",
    "internal_roi_dir = op.join(extraction_dir, \"internal_roi_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2,130 processed PET scans from 621 subjects.\n"
     ]
    }
   ],
   "source": [
    "# Load the raw_PET_index dataframe in metadata/scans_to_process, and\n",
    "# filter to retain all fully processed scans.\n",
    "keep_cols = [\n",
    "    \"subj\",\n",
    "    \"tracer\",\n",
    "    \"pet_date\",\n",
    "    \"pet_image_id\",\n",
    "    \"pet_scan_number\",\n",
    "    \"n_pet_scans\",\n",
    "    \"days_from_baseline_pet\",\n",
    "    \"days_from_last_pet\",\n",
    "    \"pet_res\",\n",
    "    \"mri_date\",\n",
    "    \"mri_image_id\",\n",
    "    \"days_mri_to_pet\",\n",
    "    \"abs_days_mri_to_pet\",\n",
    "    \"pet_proc_dir\",\n",
    "]\n",
    "pet_scan_idx = pd.read_csv(\n",
    "    glob_sort_mtime(op.join(scans_to_process_dir, \"raw_PET_index*.csv\"))[0]\n",
    ")\n",
    "pet_scans = (\n",
    "    pet_scan_idx.loc[pet_scan_idx[\"pet_processing_complete\"] == 1, keep_cols]\n",
    "    .reset_index(drop=True)\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "pet_scans = pet_scans.rename(columns={\"subj\": \"subject_id\"})\n",
    "\n",
    "# Get a list of subjects with processed PET scans\n",
    "pet_subjs = pet_scans[\"subject_id\"].unique().tolist()\n",
    "\n",
    "print(f\"Found {len(pet_scans):,} processed PET scans from {len(pet_subjs):,} subjects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbb: (1003, 14)\n",
      "ftp: (969, 14)\n",
      "fdg: (158, 14)\n"
     ]
    }
   ],
   "source": [
    "# Split the PET scans dataframe by tracer\n",
    "pets = {}\n",
    "pets[\"fbb\"] = pet_scans.query(\"(tracer=='FBB')\").copy()\n",
    "pets[\"ftp\"] = pet_scans.query(\"(tracer=='FTP')\").copy()\n",
    "pets[\"fdg\"] = pet_scans.query(\"(tracer=='FDG')\").copy()\n",
    "\n",
    "for tracer in pets:\n",
    "    print(f\"{tracer}: {pets[tracer].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PET and MRI QC files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMich PET QC\n",
    "\n",
    "Retain PET scans that passed initial QC at UMich and were deemed suitable\n",
    "for quantitative analysis\n",
    "\n",
    "- `atri/leads_codebook_study_data_amyqc.csv`\n",
    "  - Filter by columns\n",
    "    - `scanqltya` == 1\n",
    "  - Join on columns\n",
    "    - `subject_label` -> `subject_id`\n",
    "    - `scandate` -> `pet_date`\n",
    "  \n",
    "- `atri/leads_codebook_study_data_tauqc.csv`\n",
    "  - Filter by columns\n",
    "    - `scanqlty` == 1\n",
    "  - Join on columns\n",
    "    - `subject_label` -> `subject_id`\n",
    "    - `scandate` -> `pet_date`\n",
    "\n",
    "- `atri/leads_codebook_study_data_fdgqc.csv`\n",
    "  - Filter by columns:\n",
    "    - `scanqltya` == 1\n",
    "  - Join on columns\n",
    "    - `subject_label` -> `subject_id`\n",
    "    - `scandate` -> `pet_date`\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 1,003/1,003 FBB scans that passed UMich QC\n",
      "FBB: (1003, 14)\n"
     ]
    }
   ],
   "source": [
    "# Create a dict to hold UMich QC dataframes\n",
    "qc_mich = {}\n",
    "\n",
    "# !!----------------------------------!!\n",
    "# Load dataframes\n",
    "tracer = \"fbb\"\n",
    "pets[tracer] = pet_scans.query(f\"(tracer=='{tracer.upper()}')\").copy()\n",
    "qc_mich[tracer] = pd.read_csv(op.join(atri_dir, \"leads_codebook_study_data_amyqc.csv\"))\n",
    "\n",
    "# Rename columns\n",
    "qc_mich[tracer] = qc_mich[tracer].rename(\n",
    "    columns={\n",
    "        \"subject_label\": \"subject_id\",\n",
    "        \"scandate\": \"pet_date\",\n",
    "        \"scanqltya\": \"passed_umich_qc\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Select rows that passed QC\n",
    "qc_mich[tracer] = qc_mich[tracer].query(\"(passed_umich_qc==1)\")\n",
    "\n",
    "# Make sure every scan has only one row\n",
    "assert len(qc_mich[tracer]) == len(\n",
    "    qc_mich[tracer].drop_duplicates([\"subject_id\", \"pet_date\"])\n",
    ")\n",
    "\n",
    "# Select needed columns\n",
    "keep_cols = [\"subject_id\", \"pet_date\", \"passed_umich_qc\"]\n",
    "qc_mich[tracer] = qc_mich[tracer][keep_cols]\n",
    "\n",
    "# Merge into the main PET scans dataframe\n",
    "pets[tracer] = pets[tracer].merge(\n",
    "    qc_mich[tracer],\n",
    "    on=[\"subject_id\", \"pet_date\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Select scans that passed QC\n",
    "n_scans = len(pets[tracer])\n",
    "n_passed = int(pets[tracer][\"passed_umich_qc\"].sum())\n",
    "n_failed = n_scans - n_passed\n",
    "print(f\"Keeping {n_passed:,}/{n_scans:,} {tracer.upper()} scans that passed UMich QC\")\n",
    "if n_failed > 0:\n",
    "    print(\"Failed scans:\")\n",
    "    print(pets[tracer].query(\"(passed_umich_qc!=1)\")[[\"subject_id\", \"pet_date\"]])\n",
    "pets[tracer] = pets[tracer].query(\"(passed_umich_qc==1)\").reset_index(drop=True)\n",
    "pets[tracer] = pets[tracer].drop(columns=[\"passed_umich_qc\"])\n",
    "\n",
    "# Print final dataframe shape\n",
    "print(f\"{tracer.upper()}: {pets[tracer].shape}\")\n",
    "\n",
    "# !!----------------------------------!!\n",
    "# Load dataframes\n",
    "tracer = \"ftp\"\n",
    "pets[tracer] = pet_scans.query(f\"(tracer=='{tracer.upper()}')\").copy()\n",
    "qc_mich[tracer] = pd.read_csv(op.join(atri_dir, \"leads_codebook_study_data_tauqc.csv\"))\n",
    "\n",
    "# Rename columns\n",
    "qc_mich[tracer] = qc_mich[tracer].rename(\n",
    "    columns={\n",
    "        \"subject_label\": \"subject_id\",\n",
    "        \"scandate\": \"pet_date\",\n",
    "        \"scanqlty\": \"passed_umich_qc\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Select rows that passed QC\n",
    "qc_mich[tracer] = qc_mich[tracer].query(\"(passed_umich_qc==1)\")\n",
    "\n",
    "# Make sure every scan has only one row\n",
    "assert len(qc_mich[tracer]) == len(\n",
    "    qc_mich[tracer].drop_duplicates([\"subject_id\", \"pet_date\"])\n",
    ")\n",
    "\n",
    "# Select needed columns\n",
    "keep_cols = [\"subject_id\", \"pet_date\", \"passed_umich_qc\"]\n",
    "qc_mich[tracer] = qc_mich[tracer][keep_cols]\n",
    "\n",
    "# Fix a problem with one scan that was misdated\n",
    "idx = (\n",
    "    qc_mich[tracer].query(\"(subject_id=='LDS0370672') & (pet_date=='2023-09-13')\").index\n",
    ")\n",
    "qc_mich[tracer].loc[idx, \"pet_date\"] = \"2023-09-14\"\n",
    "\n",
    "# Merge into the main PET scans dataframe\n",
    "pets[tracer] = pets[tracer].merge(\n",
    "    qc_mich[tracer],\n",
    "    on=[\"subject_id\", \"pet_date\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Select scans that passed QC\n",
    "n_scans = len(pets[tracer])\n",
    "n_passed = int(pets[tracer][\"passed_umich_qc\"].sum())\n",
    "n_failed = n_scans - n_passed\n",
    "print(f\"Keeping {n_passed:,}/{n_scans:,} {tracer.upper()} scans that passed UMich QC\")\n",
    "if n_failed > 0:\n",
    "    print(\"Failed scans:\")\n",
    "    print(pets[tracer].query(\"(passed_umich_qc!=1)\")[[\"subject_id\", \"pet_date\"]])\n",
    "pets[tracer] = pets[tracer].query(\"(passed_umich_qc==1)\").reset_index(drop=True)\n",
    "pets[tracer] = pets[tracer].drop(columns=[\"passed_umich_qc\"])\n",
    "\n",
    "# Print final dataframe shape\n",
    "print(f\"{tracer.upper()}: {pets[tracer].shape}\")\n",
    "\n",
    "# !!----------------------------------!!\n",
    "# Load dataframes\n",
    "tracer = \"fdg\"\n",
    "pets[tracer] = pet_scans.query(f\"(tracer=='{tracer.upper()}')\").copy()\n",
    "qc_mich[tracer] = pd.read_csv(op.join(atri_dir, \"leads_codebook_study_data_fdgqc.csv\"))\n",
    "\n",
    "# Rename columns\n",
    "qc_mich[tracer] = qc_mich[tracer].rename(\n",
    "    columns={\n",
    "        \"subject_label\": \"subject_id\",\n",
    "        \"scandate\": \"pet_date\",\n",
    "        \"scanqltya\": \"passed_umich_qc\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Select rows that passed QC\n",
    "qc_mich[tracer] = qc_mich[tracer].query(\"(passed_umich_qc==1)\")\n",
    "\n",
    "# Make sure every scan has only one row\n",
    "assert len(qc_mich[tracer]) == len(\n",
    "    qc_mich[tracer].drop_duplicates([\"subject_id\", \"pet_date\"])\n",
    ")\n",
    "\n",
    "# Select needed columns\n",
    "keep_cols = [\"subject_id\", \"pet_date\", \"passed_umich_qc\"]\n",
    "qc_mich[tracer] = qc_mich[tracer][keep_cols]\n",
    "\n",
    "# Fix a problem with one scan that was misdated\n",
    "idx = (\n",
    "    qc_mich[tracer].query(\"(subject_id=='LDS0370012') & (pet_date=='2020-12-17')\").index\n",
    ")\n",
    "qc_mich[tracer].loc[idx, \"pet_date\"] = \"2020-12-15\"\n",
    "\n",
    "# Merge into the main PET scans dataframe\n",
    "pets[tracer] = pets[tracer].merge(\n",
    "    qc_mich[tracer],\n",
    "    on=[\"subject_id\", \"pet_date\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Select scans that passed QC\n",
    "n_scans = len(pets[tracer])\n",
    "n_passed = int(pets[tracer][\"passed_umich_qc\"].sum())\n",
    "n_failed = n_scans - n_passed\n",
    "print(f\"Keeping {n_passed:,}/{n_scans:,} {tracer.upper()} scans that passed UMich QC\")\n",
    "if n_failed > 0:\n",
    "    print(\"Failed scans:\")\n",
    "    print(pets[tracer].query(\"(passed_umich_qc!=1)\")[[\"subject_id\", \"pet_date\"]])\n",
    "pets[tracer] = pets[tracer].query(\"(passed_umich_qc==1)\").reset_index(drop=True)\n",
    "pets[tracer] = pets[tracer].drop(columns=[\"passed_umich_qc\"])\n",
    "\n",
    "# Print final dataframe shape\n",
    "print(f\"{tracer.upper()}: {pets[tracer].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCSF PET QC\n",
    "\n",
    "Retain PET scans that passed post-processing QC at UCSF, for which\n",
    "PET SUVR means in FreeSurfer ROIs in native MRI space can be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI: (1155, 6)\n",
      "FBB: (997, 8)\n",
      "FTP: (959, 8)\n",
      "FDG: (158, 7)\n"
     ]
    }
   ],
   "source": [
    "# Load UCSF QC spreadsheets\n",
    "qc_ucsf_file = glob_sort_mtime(\n",
    "    op.join(proj_dir, \"metadata\", \"qc\", \"ssheets\", \"LEADS_QC*.xlsx\")\n",
    ")[0]\n",
    "\n",
    "# Create a dict to hold UCSF QC dataframes\n",
    "qc_ucsf = {\n",
    "    \"mri\": pd.read_excel(qc_ucsf_file, sheet_name=\"MRI\"),\n",
    "    \"fbb\": pd.read_excel(qc_ucsf_file, sheet_name=\"FBB\"),\n",
    "    \"ftp\": pd.read_excel(qc_ucsf_file, sheet_name=\"FTP\"),\n",
    "    \"fdg\": pd.read_excel(qc_ucsf_file, sheet_name=\"FDG\"),\n",
    "}\n",
    "\n",
    "# Rename columns\n",
    "for scan_type in qc_ucsf:\n",
    "    if scan_type == \"mri\":\n",
    "        qc_ucsf[scan_type] = qc_ucsf[scan_type].rename(\n",
    "            columns={\n",
    "                \"subj\": \"subject_id\",\n",
    "                \"scan_date\": \"mri_date\",\n",
    "                \"notes\": \"mri_qc_notes\",\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        qc_ucsf[scan_type] = qc_ucsf[scan_type].rename(\n",
    "            columns={\n",
    "                \"subj\": \"subject_id\",\n",
    "                \"scan_date\": \"pet_date\",\n",
    "                \"notes\": \"pet_qc_notes\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Drop unnecessary columns\n",
    "for scan_type in qc_ucsf:\n",
    "    if scan_type == \"mri\":\n",
    "        drop_cols = [\n",
    "            \"rater\",\n",
    "            \"spm_seg_ok\",\n",
    "            \"affine_nu_ok\",\n",
    "            \"flag_for_consensus\",\n",
    "            \"qc_done\",\n",
    "        ]\n",
    "        qc_ucsf[scan_type] = qc_ucsf[scan_type].drop(columns=drop_cols)\n",
    "    else:\n",
    "        drop_cols = [\n",
    "            \"rater\",\n",
    "            \"affine_pet_ok\",\n",
    "            \"flag_for_consensus\",\n",
    "            \"qc_done\",\n",
    "        ]\n",
    "        qc_ucsf[scan_type] = qc_ucsf[scan_type].drop(columns=drop_cols)\n",
    "\n",
    "# Convert datetime to string format\n",
    "for scan_type in qc_ucsf:\n",
    "    if scan_type == \"mri\":\n",
    "        qc_ucsf[scan_type][\"mri_date\"] = qc_ucsf[scan_type][\"mri_date\"].dt.strftime(\n",
    "            \"%Y-%m-%d\"\n",
    "        )\n",
    "    else:\n",
    "        qc_ucsf[scan_type][\"pet_date\"] = qc_ucsf[scan_type][\"pet_date\"].dt.strftime(\n",
    "            \"%Y-%m-%d\"\n",
    "        )\n",
    "\n",
    "# Add QC pass columns\n",
    "scan_type = \"mri\"\n",
    "qc_ucsf[scan_type].insert(\n",
    "    2,\n",
    "    \"mri_qc_pass\",\n",
    "    qc_ucsf[scan_type].apply(\n",
    "        lambda x: np.all(\n",
    "            (x[\"native_nu_rating\"] > 0, x[\"aparc+aseg_rating\"] > 0)\n",
    "        ).astype(float),\n",
    "        axis=1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "scan_type = \"fbb\"\n",
    "qc_ucsf[scan_type].insert(\n",
    "    2,\n",
    "    \"pet_qc_pass\",\n",
    "    qc_ucsf[scan_type].apply(\n",
    "        lambda x: np.all(\n",
    "            (\n",
    "                x[\"native_pet_ok\"] > 0,\n",
    "                x[\"pet_to_mri_coreg_ok\"] > 0,\n",
    "                x[\"wcbl_mask_ok\"] > 0,\n",
    "            )\n",
    "        ).astype(float),\n",
    "        axis=1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "scan_type = \"ftp\"\n",
    "qc_ucsf[scan_type].insert(\n",
    "    2,\n",
    "    \"pet_qc_pass\",\n",
    "    qc_ucsf[scan_type].apply(\n",
    "        lambda x: np.all(\n",
    "            (\n",
    "                x[\"native_pet_ok\"] > 0,\n",
    "                x[\"pet_to_mri_coreg_ok\"] > 0,\n",
    "                x[\"infcblgm_mask_ok\"] > 0,\n",
    "            )\n",
    "        ).astype(float),\n",
    "        axis=1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "scan_type = \"fdg\"\n",
    "qc_ucsf[scan_type].insert(\n",
    "    2,\n",
    "    \"pet_qc_pass\",\n",
    "    qc_ucsf[scan_type].apply(\n",
    "        lambda x: np.all(\n",
    "            (\n",
    "                x[\"native_pet_ok\"] > 0,\n",
    "                x[\"pet_to_mri_coreg_ok\"] > 0,\n",
    "                x[\"pons_mask_ok\"] > 0,\n",
    "            )\n",
    "        ).astype(float),\n",
    "        axis=1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Merge the UCSF QC data into the PET scans dataframes\n",
    "for tracer in pets:\n",
    "pets[tracer] = pets[tracer].merge(\n",
    "    qc_ucsf[tracer],\n",
    "    on=[\"subject_id\", \"pet_date\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "pets[tracer] = pets[tracer].merge(\n",
    "    qc_ucsf[\"mri\"],\n",
    "    on=[\"subject_id\", \"mri_date\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Add a qc_pass column combining MRI and PET QC fields\n",
    "pets[tracer][\"qc_pass\"] = pets[tracer].apply(\n",
    "    lambda x: np.all(\n",
    "        (\n",
    "            x[\"mri_qc_pass\"] > 0,\n",
    "            x[\"pet_qc_pass\"] > 0,\n",
    "        )\n",
    "    ).astype(float),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Print how many scans passed both MRI and PET QC\n",
    "for tracer in pets:\n",
    "    n_scans = len(pets[tracer])\n",
    "    n_passed = int(pets[tracer][\"qc_pass\"].sum())\n",
    "    print(\n",
    "        f\"{n_passed:,}/{n_scans:,} {tracer.upper()} ({n_passed/n_scans:.1%}) scans passed QC\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed PET CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference region means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>pet_date</th>\n",
       "      <th>ScalingFactor_wcbl</th>\n",
       "      <th>ScalingFactor_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDS0070120</td>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>1.144041</td>\n",
       "      <td>1.739354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id    pet_date  ScalingFactor_wcbl  ScalingFactor_composite\n",
       "0  LDS0070120  2019-06-19            1.144041                 1.739354"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ref_regions = [op.basename(f).split(\"_\")[3].split(\".\")[0].replace(\"mask-\", \"\") for f in load_ref_region_means_file(find_ref_region_means_file(dd)).loc[1, \"mask_file\"].split(\";\")]\n",
    "# if len(ref_regions) > 1:\n",
    "#     ref_region = \"composite\"\n",
    "# else:\n",
    "#     ref_region = ref_regions[0]\n",
    "\n",
    "# load_ref_region_means_file(find_ref_region_means_file(dd))\n",
    "\n",
    "get_ref_region_means(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pet_proc_dir(pet_proc_dir):\n",
    "    \"\"\"Return subject, tracer, and PET date from the PET proc dir.\"\"\"\n",
    "    subj = op.basename(op.dirname(pet_proc_dir))\n",
    "    tracer, pet_date = op.basename(pet_proc_dir).split(\"_\")\n",
    "    return subj, tracer, pet_date\n",
    "\n",
    "\n",
    "def get_ref_region_means(pet_proc_dir):\n",
    "    try:\n",
    "        rr_dat = format_ref_region_means(\n",
    "            load_ref_region_means_file(find_ref_region_means_file(pet_proc_dir))\n",
    "        )\n",
    "        return rr_dat\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_ref_region_means_file(pet_proc_dir):\n",
    "    \"\"\"Return the filepath to the ROI mean CSV file.\"\"\"\n",
    "    subj, tracer, pet_date = parse_pet_proc_dir(pet_proc_dir)\n",
    "    filepath = op.join(\n",
    "        pet_proc_dir,\n",
    "        f\"{subj}_{tracer}_{pet_date}_ref-region-means.csv\",\n",
    "    )\n",
    "    if op.isfile(filepath):\n",
    "        return filepath\n",
    "    else:\n",
    "        warnings.warn(f\"File not found: {filepath}\")\n",
    "\n",
    "\n",
    "def load_ref_region_means_file(filepath):\n",
    "    \"\"\"Load and format the ROI extractions CSV file.\"\"\"\n",
    "\n",
    "    def _scrape_ref_regions(mask_file):\n",
    "        ref_regions = [\n",
    "            op.basename(x).split(\".\")[0].split(\"_\")[3].split(\"-\")[1]\n",
    "            for x in mask_file.split(\";\")\n",
    "        ]\n",
    "        if len(ref_regions) > 1:\n",
    "            return \"compwm\"\n",
    "        else:\n",
    "            return ref_regions[0]\n",
    "\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Parse the PET proc dir\n",
    "    subj, _, pet_date = parse_pet_proc_dir(op.dirname(filepath))\n",
    "\n",
    "    # Add subject_id and pet_date columns\n",
    "    df.insert(0, \"subject_id\", subj)\n",
    "    df.insert(1, \"pet_date\", pet_date)\n",
    "    df.insert(\n",
    "        2,\n",
    "        \"ref_region\",\n",
    "        df[\"mask_file\"].apply(_scrape_ref_regions),\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_ref_region_means(df):\n",
    "    \"\"\"Format ROI extractions dataframe for LEADS quarterly reports.\"\"\"\n",
    "    # Format ROI names\n",
    "    df[\"ref_region\"] = df[\"ref_region\"].apply(lambda x: x.replace(\"-\", \"_\"))\n",
    "    df[\"ref_region\"] = df[\"ref_region\"].astype(\n",
    "        pd.CategoricalDtype(df[\"ref_region\"], ordered=True)\n",
    "    )\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    df = df.drop(columns=[\"image_file\", \"mask_file\", \"voxel_count\"])\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"mean\": \"ScalingFactor\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Pivot the dataframe from long to wide format\n",
    "    df = df.set_index([\"subject_id\", \"pet_date\", \"ref_region\"]).unstack(\"ref_region\")\n",
    "\n",
    "    # Flatten the column index\n",
    "    df.columns = [\"_\".join(col).strip() for col in df.columns.values]\n",
    "\n",
    "    # Reset the index\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBB: (1003, 4)\n",
      "FTP: (969, 4)\n",
      "FDG: (158, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load reference region scaling factors for each tracer\n",
    "ref_region_dat = {}\n",
    "for tracer in pets:\n",
    "    ref_region_dat[tracer] = pd.concat(\n",
    "        list(\n",
    "            pets[tracer].apply(\n",
    "                lambda x: get_ref_region_means(x[\"pet_proc_dir\"]), axis=1\n",
    "            )\n",
    "        ),\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    print(f\"{tracer.upper()}: {ref_region_dat[tracer].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi_extractions(pet_proc_dir, ref_region):\n",
    "    try:\n",
    "        roi_dat = format_roi_extractions(\n",
    "            load_roi_extractions_file(\n",
    "                find_roi_extractions_file(pet_proc_dir, ref_region)\n",
    "            )\n",
    "        )\n",
    "        return roi_dat\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_roi_extractions_file(pet_proc_dir, ref_region):\n",
    "    \"\"\"Return the filepath to the ROI mean CSV file.\"\"\"\n",
    "    subj, tracer, pet_date = parse_pet_proc_dir(pet_proc_dir)\n",
    "    filepath = op.join(\n",
    "        pet_proc_dir,\n",
    "        f\"r{subj}_{tracer}_{pet_date}_suvr-{ref_region}_roi-extractions.csv\",\n",
    "    )\n",
    "    if op.isfile(filepath):\n",
    "        return filepath\n",
    "    else:\n",
    "        warnings.warn(f\"File not found: {filepath}\")\n",
    "\n",
    "\n",
    "def load_roi_extractions_file(filepath):\n",
    "    \"\"\"Load and format the ROI extractions CSV file.\"\"\"\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Add subject_id and pet_date columns\n",
    "    df.insert(\n",
    "        0,\n",
    "        \"subject_id\",\n",
    "        df[\"image_file\"].apply(lambda x: op.basename(x).split(\"_\")[0][1:]),\n",
    "    )\n",
    "    df.insert(\n",
    "        1, \"pet_date\", df[\"image_file\"].apply(lambda x: op.basename(x).split(\"_\")[2])\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_roi_extractions(df):\n",
    "    \"\"\"Format ROI extractions dataframe for LEADS quarterly reports.\"\"\"\n",
    "    # Format ROI names\n",
    "    df[\"roi\"] = df[\"roi\"].apply(lambda x: x.replace(\"-\", \"_\"))\n",
    "    df[\"roi\"] = df[\"roi\"].astype(pd.CategoricalDtype(df[\"roi\"], ordered=True))\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    df = df.drop(columns=[\"image_file\", \"roi_file\"])\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"mean\": \"MRIBASED_SUVR\",\n",
    "            \"voxel_count\": \"ClustSize\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Pivot the dataframe from long to wide format\n",
    "    df = df.set_index([\"subject_id\", \"pet_date\", \"roi\"]).unstack(\"roi\")\n",
    "\n",
    "    # Flatten the column index\n",
    "    df.columns = [\"_\".join(col[::-1]).strip() for col in df.columns.values]\n",
    "\n",
    "    # Reset the index\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBB: (1003, 226)\n",
      "FTP: (969, 230)\n",
      "FDG: (158, 228)\n"
     ]
    }
   ],
   "source": [
    "# Define reference regions for each tracer\n",
    "ref_regions = {\n",
    "    \"fbb\": \"wcbl\",\n",
    "    \"ftp\": \"infcblgm\",\n",
    "    \"fdg\": \"pons\",\n",
    "}\n",
    "\n",
    "# Load ROI extractions for each tracer\n",
    "roi_dat = {}\n",
    "for tracer, ref_region in ref_regions.items():\n",
    "    roi_dat[tracer] = pd.concat(\n",
    "        list(\n",
    "            pets[tracer].apply(\n",
    "                lambda x: get_roi_extractions(x[\"pet_proc_dir\"], ref_region), axis=1\n",
    "            )\n",
    "        ),\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    print(f\"{tracer.upper()}: {roi_dat[tracer].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centiloids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_centiloid_csv(filepath):\n",
    "    \"\"\"Load and format the Centiloid CSV file.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df[\"image_file\"] = df[\"image_file\"].apply(op.basename)\n",
    "    df.insert(0, \"subj\", df[\"image_file\"].apply(lambda x: x.split(\"_\")[0][1:]))\n",
    "    df.insert(1, \"pet_date\", df[\"image_file\"].apply(lambda x: x.split(\"_\")[2]))\n",
    "    df = df.loc[\n",
    "        df[\"image_file\"].apply(lambda x: x.split(\"_\")[3].startswith(\"suvr-wcbl\")), :\n",
    "    ]\n",
    "    df = df.drop(columns=[\"image_file\", \"mask_file\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_centiloids(pet_proc_dir):\n",
    "    try:\n",
    "        rr_dat = format_centiloid_dat(\n",
    "            load_centiloid_file(find_centiloid_file(pet_proc_dir))\n",
    "        )\n",
    "        return rr_dat\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_centiloid_file(pet_proc_dir):\n",
    "    \"\"\"Return the filepath to the ROI mean CSV file.\"\"\"\n",
    "    subj, tracer, pet_date = parse_pet_proc_dir(pet_proc_dir)\n",
    "    filepath = op.join(\n",
    "        pet_proc_dir,\n",
    "        f\"{subj}_{tracer}_{pet_date}_amyloid-cortical-summary.csv\",\n",
    "    )\n",
    "    if op.isfile(filepath):\n",
    "        return filepath\n",
    "    else:\n",
    "        warnings.warn(f\"File not found: {filepath}\")\n",
    "\n",
    "\n",
    "def load_centiloid_file(filepath):\n",
    "    \"\"\"Load and format the ROI extractions CSV file.\"\"\"\n",
    "\n",
    "    def _scrape_ref_region(image_file):\n",
    "        ref_region = op.basename(image_file).split(\".\")[0].split(\"_\")[3].split(\"-\")[1]\n",
    "        return ref_region\n",
    "\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Parse the PET proc dir\n",
    "    subj, _, pet_date = parse_pet_proc_dir(op.dirname(filepath))\n",
    "\n",
    "    # Add subject_id and pet_date columns\n",
    "    df.insert(0, \"subject_id\", subj)\n",
    "    df.insert(1, \"pet_date\", pet_date)\n",
    "    df.insert(\n",
    "        2,\n",
    "        \"ref_region\",\n",
    "        df[\"image_file\"].apply(_scrape_ref_region),\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_centiloid_dat(df):\n",
    "    \"\"\"Format ROI extractions dataframe for LEADS quarterly reports.\"\"\"\n",
    "    # Format ROI names\n",
    "    df[\"ref_region\"] = df[\"ref_region\"].apply(lambda x: x.replace(\"-\", \"_\"))\n",
    "    df[\"ref_region\"] = df[\"ref_region\"].astype(\n",
    "        pd.CategoricalDtype(df[\"ref_region\"], ordered=True)\n",
    "    )\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    df = df.drop(columns=[\"image_file\", \"mask_file\", \"mean_suvr\"])\n",
    "\n",
    "    # Pivot the dataframe from long to wide format\n",
    "    df = df.set_index([\"subject_id\", \"pet_date\", \"ref_region\"]).unstack(\"ref_region\")\n",
    "\n",
    "    # Flatten the column index\n",
    "    df.columns = [\"_\".join(col).strip()[::-1] for col in df.columns.values]\n",
    "\n",
    "    # Reset the index\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBB: (1003, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load Centiloid values for amyloid PET\n",
    "tracer = \"fbb\"\n",
    "centiloid_dat = pd.concat(\n",
    "    list(pets[tracer].apply(lambda x: get_centiloids(x[\"pet_proc_dir\"]), axis=1)),\n",
    "    ignore_index=True,\n",
    ")\n",
    "print(f\"{tracer.upper()}: {centiloid_dat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject-level data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohort assignment\n",
    "\n",
    "Determine each participant's enrollment status as a control or patient.\n",
    "For patients, determine their diagnostic assignment into EOAD or EOnonAD\n",
    "groups based on visual read of the baseline amyloid PET scan.\n",
    "\n",
    "- `atri/leads_codebook_study_data_subject.csv`\n",
    "  - Join on columns\n",
    "    - `subject_label` -> `subject_id`\n",
    "  - Include columns\n",
    "    - `ptcoh` -> `study_cohort`\n",
    "      - 1 = \"Control\" (cognitively normal)\n",
    "      - 2 = \"Patient\" (cognitively impaired)\n",
    "\n",
    "- `atri/leads_codebook_study_data_amyelg.csv`\n",
    "  - Filter by columns\n",
    "    - `event_code` == \"sc\"\n",
    "  - Join on columns\n",
    "    - `subject_label` -> `subject_id`\n",
    "  - Include columns\n",
    "    - `amyelg` -> `CohortAssgn`\n",
    "        - 0 = \"EOnonAD\"\n",
    "        - 1 = \"EOAD\"\n",
    "    - `suvr` -> `Screening_PETONLY_Composite_SUVR`\n",
    "    - `outcome` -> `Screening_PETONLY_VisualRead`\n",
    "    - `consensres` -> `Screening_PETONLY_Final_Read`\n",
    "  - Add columns\n",
    "      - `Screening_PETONLY_AmyPos_Quantification_1p18`\n",
    "      - `Screening_PETONLY_Disagreement`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screening: (621, 7)\n",
      "  subject_id\n",
      "  Screening_PETONLY_Composite_SUVR\n",
      "  Screening_PETONLY_AmyPos_Quantification_1p18\n",
      "  Screening_PETONLY_VisualRead\n",
      "  Screening_PETONLY_Disagreement\n",
      "  Screening_PETONLY_Final_Read\n",
      "  CohortAssgn\n",
      "subj_dat: (621, 2)\n",
      "  subject_id\n",
      "  CohortAssgn\n"
     ]
    }
   ],
   "source": [
    "# Initialize the subjects dataframe\n",
    "subj_dat = pd.DataFrame(pet_subjs, columns=[\"subject_id\"])\n",
    "aux = {}\n",
    "\n",
    "# !!----------------------------------!!\n",
    "# Load the cohort dataframe\n",
    "aux[\"cohort\"] = pd.read_csv(op.join(atri_dir, \"leads_codebook_study_data_subject.csv\"))\n",
    "\n",
    "# Rename columns\n",
    "aux[\"cohort\"] = aux[\"cohort\"].rename(\n",
    "    columns={\"subject_label\": \"subject_id\", \"ptcoh\": \"study_group\"}\n",
    ")\n",
    "\n",
    "# Map integer values to string labels for the study_group column\n",
    "aux[\"cohort\"][\"study_group\"] = aux[\"cohort\"][\"study_group\"].map({1: \"CN\", 2: \"PT\"})\n",
    "\n",
    "# Select needed columns\n",
    "keep_cols = [\"subject_id\", \"study_group\"]\n",
    "aux[\"cohort\"] = aux[\"cohort\"][keep_cols]\n",
    "\n",
    "# Merge into the main subject dataframe\n",
    "subj_dat = subj_dat.merge(\n",
    "    aux[\"cohort\"],\n",
    "    on=\"subject_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# !!----------------------------------!!\n",
    "# Load the amyloid eligibility dataframe\n",
    "aux[\"amyelg\"] = pd.read_csv(op.join(atri_dir, \"leads_codebook_study_data_amyelg.csv\"))\n",
    "\n",
    "# Rename columns\n",
    "aux[\"amyelg\"] = aux[\"amyelg\"].rename(\n",
    "    columns={\n",
    "        \"subject_label\": \"subject_id\",\n",
    "        \"suvr\": \"Screening_PETONLY_Composite_SUVR\",\n",
    "        \"outcome\": \"Screening_PETONLY_VisualRead\",\n",
    "        \"consensres\": \"Screening_PETONLY_Final_Read\",\n",
    "        \"amyelg\": \"CohortAssgn\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Select rows from Screening visits\n",
    "aux[\"amyelg\"] = aux[\"amyelg\"].query(\"(event_code=='sc')\")\n",
    "\n",
    "# Add additional columns\n",
    "FBB_PETONLY_THRESH = 1.18\n",
    "aux[\"amyelg\"][\"Screening_PETONLY_AmyPos_Quantification_1p18\"] = (\n",
    "    aux[\"amyelg\"][\"Screening_PETONLY_Composite_SUVR\"] > FBB_PETONLY_THRESH\n",
    ").astype(int)\n",
    "aux[\"amyelg\"][\"Screening_PETONLY_Disagreement\"] = np.logical_xor(\n",
    "    aux[\"amyelg\"][\"Screening_PETONLY_AmyPos_Quantification_1p18\"],\n",
    "    aux[\"amyelg\"][\"Screening_PETONLY_VisualRead\"],\n",
    ").astype(int)\n",
    "\n",
    "# Replace nans in Screening_PETONLY_Final_Read with\n",
    "# Screening_PETONLY_VisualRead values\n",
    "aux[\"amyelg\"][\"Screening_PETONLY_Final_Read\"] = aux[\"amyelg\"].apply(\n",
    "    lambda x: (\n",
    "        x[\"Screening_PETONLY_Final_Read\"]\n",
    "        if pd.notnull(x[\"Screening_PETONLY_Final_Read\"])\n",
    "        else x[\"Screening_PETONLY_VisualRead\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Map integer values to string labels\n",
    "aux[\"amyelg\"][\"CohortAssgn\"] = aux[\"amyelg\"][\"CohortAssgn\"].map(\n",
    "    {0: \"EOnonAD\", 1: \"EOAD\"}\n",
    ")\n",
    "\n",
    "# Select neeeded columns\n",
    "keep_cols = [\n",
    "    \"subject_id\",\n",
    "    \"Screening_PETONLY_Composite_SUVR\",\n",
    "    \"Screening_PETONLY_AmyPos_Quantification_1p18\",\n",
    "    \"Screening_PETONLY_VisualRead\",\n",
    "    \"Screening_PETONLY_Disagreement\",\n",
    "    \"Screening_PETONLY_Final_Read\",\n",
    "    \"CohortAssgn\",\n",
    "]\n",
    "aux[\"amyelg\"] = aux[\"amyelg\"][keep_cols]\n",
    "\n",
    "# Merge into the main subject dataframe\n",
    "subj_dat = subj_dat.merge(\n",
    "    aux[\"amyelg\"],\n",
    "    on=\"subject_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Combine the two diagnosis columns\n",
    "subj_dat[\"CohortAssgn\"] = subj_dat.apply(\n",
    "    lambda x: x[\"CohortAssgn\"] if pd.notnull(x[\"CohortAssgn\"]) else x[\"study_group\"],\n",
    "    axis=1,\n",
    ")\n",
    "subj_dat = subj_dat.drop(columns=[\"study_group\"])\n",
    "\n",
    "# Create the screening dataframe and drop unnecessary columns from the\n",
    "# subjects dataframe\n",
    "screening = subj_dat.copy()\n",
    "keep_cols = [\"subject_id\", \"CohortAssgn\"]\n",
    "subj_dat = subj_dat[keep_cols]\n",
    "\n",
    "# !!----------------------------------!!\n",
    "# Print dataframe shapes and column names\n",
    "print(f\"screening: {screening.shape}\")\n",
    "print(\"  \" + \"\\n  \".join(screening.columns.tolist()))\n",
    "print(f\"subj_dat: {subj_dat.shape}\")\n",
    "print(\"  \" + \"\\n  \".join(subj_dat.columns.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Participant demographics\n",
    "\n",
    "Determine each participant's date of birth, sex, race and ethnicity, and years of education\n",
    "\n",
    "- `loni/LEADS_PTDEMOG*.csv`\n",
    "  - Join on columns\n",
    "    - `subject_code` -> `subject_id`\n",
    "  - Include columns\n",
    "    - `ptdob` -> `dob`\n",
    "    - `ptgender` -> `sex`\n",
    "      - 1 = \"Male\"\n",
    "      - 2 = \"Female\"\n",
    "    - `ptraccat` -> `race`\n",
    "      - 1 = \"American Indian or Alaskan Native\"\n",
    "      - 2 = \"Asian\"\n",
    "      - 3 = \"Native Hawaiian or Other Pacific Islander\"\n",
    "      - 4 = \"Black or African American\"\n",
    "      - 5 = \"White\"\n",
    "      - 6 = \"More than one race\"\n",
    "      - 7 = \"Unknown\"\n",
    "    - `ptethcat` -> `ethnicity`\n",
    "      - 1 = \"Hispanic or Latino\"\n",
    "      - 2 = \"Not Hispanic or Latino\"\n",
    "      - 3 = \"Unknown\"\n",
    "    - `pteducat` -> `years_education`\n",
    "      - Years of education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj_dat: (621, 7)\n",
      "  subject_id\n",
      "  CohortAssgn\n",
      "  dob\n",
      "  sex\n",
      "  race\n",
      "  ethnicity\n",
      "  years_education\n"
     ]
    }
   ],
   "source": [
    "# !!----------------------------------!!\n",
    "# Load the dataframe\n",
    "aux[\"demo\"] = pd.read_csv(glob_sort_mtime(op.join(loni_dir, \"LEADS_PTDEMOG*.csv\"))[0])\n",
    "\n",
    "# Rename columns\n",
    "aux[\"demo\"] = aux[\"demo\"].rename(\n",
    "    columns={\n",
    "        \"subject_code\": \"subject_id\",\n",
    "        \"ptdob\": \"dob\",\n",
    "        \"ptgender\": \"sex\",\n",
    "        \"ptraccat\": \"race\",\n",
    "        \"ptethcat\": \"ethnicity\",\n",
    "        \"pteducat\": \"years_education\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Capitalize subject IDs\n",
    "aux[\"demo\"][\"subject_id\"] = aux[\"demo\"][\"subject_id\"].str.upper()\n",
    "\n",
    "# Map integer values to string labels\n",
    "aux[\"demo\"][\"sex\"] = aux[\"demo\"][\"sex\"].map({1: \"Male\", 2: \"Female\"})\n",
    "aux[\"demo\"][\"race\"] = aux[\"demo\"][\"race\"].map(\n",
    "    {\n",
    "        1: \"American Indian or Alaskan Native\",\n",
    "        2: \"Asian\",\n",
    "        3: \"Native Hawaiian or Other Pacific Islander\",\n",
    "        4: \"Black or African American\",\n",
    "        5: \"White\",\n",
    "        6: \"More than one race\",\n",
    "        7: \"Unknown\",\n",
    "    }\n",
    ")\n",
    "aux[\"demo\"][\"ethnicity\"] = aux[\"demo\"][\"ethnicity\"].map(\n",
    "    {\n",
    "        1: \"Hispanic or Latino\",\n",
    "        2: \"Not Hispanic or Latino\",\n",
    "        3: \"Unknown\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Select needed columns\n",
    "keep_cols = [\"subject_id\", \"dob\", \"sex\", \"race\", \"ethnicity\", \"years_education\"]\n",
    "aux[\"demo\"] = aux[\"demo\"][keep_cols]\n",
    "\n",
    "# Merge into the main subject dataframe\n",
    "subj_dat = subj_dat.merge(\n",
    "    aux[\"demo\"],\n",
    "    on=\"subject_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "print(f\"subj_dat: {subj_dat.shape}\")\n",
    "print(\"  \" + \"\\n  \".join(subj_dat.columns.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline clinical characteristics\n",
    "\n",
    "Determine each patient's clinical severity (MCI or Dementia), cognitive\n",
    "test scores (MMSE, CDR), and clinical phenotype at baseline.\n",
    "\n",
    "- `atri/leads_codebook_study_data_prelimdx.csv`\n",
    "  - Filter by columns\n",
    "    - `event_code` == \"sc\"\n",
    "  - Join on columns\n",
    "    - `subject_label` -> `subject_id`\n",
    "  - Include columns\n",
    "    - `dementia` -> `clinical_severity_baseline`\n",
    "      - 0 = \"MCI\"\n",
    "      - 1 = \"Dementia\"\n",
    "\n",
    "- `atri/leads_codebook_study_data_mmse.csv`\n",
    "  - Filter by columns\n",
    "    - `event_code` == \"sc\"\n",
    "  - Join on columns\n",
    "    - `subject_label` -> `subject_id`\n",
    "  - Include columns\n",
    "    - `mmscore` -> `mmse_baseline`\n",
    "\n",
    "- `loni/Clinical_Dementia_Rating*.csv`\n",
    "  - Filter by columns\n",
    "    - `LEADS_SCREENING_VISIT` == \"sc\"\n",
    "  - Join on columns\n",
    "    - `LEADS_ID` -> `subject_id`\n",
    "  - Include columns\n",
    "    - `C2VISITYR`\n",
    "    - `C2VISITMO`\n",
    "    - `C2VISITDAY`\n",
    "    - `CDRGLOB` -> `cdr_global_baseline`\n",
    "    - `CDRSUM` -> `cdr_sb_baseline`\n",
    "  - Add columns\n",
    "    - `cdr_date`\n",
    "\n",
    "- `atri/leads_codebook_study_data_pcadx.csv`\n",
    "  - Filter by columns\n",
    "      - `event_code` == \"sc\"\n",
    "  - Join on columns\n",
    "      - `subject_label` -> `subject_id`\n",
    "  - Include columns\n",
    "      - `pcaformal` -> `pca_formal`\n",
    "        - 0 = \"Does not meet formal clinical diagnostic criteria for PCA\"\n",
    "        - 1 = \"Meets formal clinical diagnostic criteria for PCA\"\n",
    "\n",
    "- `atri/leads_codebook_study_data_ppadx.csv`\n",
    "  - Filter by columns\n",
    "      - `event_code` == \"sc\"\n",
    "  - Join on columns\n",
    "      - `subject_label` -> `subject_id`\n",
    "  - Include columns\n",
    "      - `lvppaformal` -> `lvppa_formal`\n",
    "        - 0 = \"Does not meet formal clinical diagnostic criteria for lvPPA\"\n",
    "        - 1 = \"Meets formal clinical diagnostic criteria for lvPPA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - `atri/leads_codebook_study_data_prelimdx.csv`\n",
    "#   - Filter by columns\n",
    "#     - `event_code` == \"sc\"\n",
    "#   - Join on columns\n",
    "#     - `subject_label` -> `subject_id`\n",
    "#   - Include columns\n",
    "#     - `dementia` -> `clinical_severity_baseline`\n",
    "#       - 0 = \"MCI\"\n",
    "#       - 1 = \"Dementia\"\n",
    "# !!----------------------------------!!\n",
    "# Load the dataframe\n",
    "aux[\"prelimdx\"] = pd.read_csv(\n",
    "    op.join(atri_dir, \"leads_codebook_study_data_prelimdx.csv\")\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "aux[\"\"] = aux[\"\"].rename(columns={})\n",
    "\n",
    "# Map integer values to string labels\n",
    "aux[\"\"][\"\"] = aux[\"\"][\"\"].map({})\n",
    "\n",
    "# Select needed columns\n",
    "keep_cols = [\"\"]\n",
    "aux[\"\"] = aux[\"\"][keep_cols]\n",
    "\n",
    "# Merge into the main subject dataframe\n",
    "subj_dat = subj_dat.merge(\n",
    "    aux[\"\"],\n",
    "    on=\"subject_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# - `atri/leads_codebook_study_data_mmse.csv`\n",
    "#   - Filter by columns\n",
    "#     - `event_code` == \"sc\"\n",
    "#   - Join on columns\n",
    "#     - `subject_label` -> `subject_id`\n",
    "#   - Include columns\n",
    "#     - `mmscore` -> `mmse_baseline`\n",
    "# !!----------------------------------!!\n",
    "# Load the dataframe\n",
    "aux[\"prelimdx\"] = pd.read_csv(\n",
    "    op.join(atri_dir, \"leads_codebook_study_data_prelimdx.csv\")\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "aux[\"\"] = aux[\"\"].rename(columns={})\n",
    "\n",
    "# Map integer values to string labels\n",
    "aux[\"\"][\"\"] = aux[\"\"][\"\"].map({})\n",
    "\n",
    "# Select needed columns\n",
    "keep_cols = [\"\"]\n",
    "aux[\"\"] = aux[\"\"][keep_cols]\n",
    "\n",
    "# Merge into the main subject dataframe\n",
    "subj_dat = subj_dat.merge(\n",
    "    aux[\"\"],\n",
    "    on=\"subject_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# - `loni/Clinical_Dementia_Rating*.csv`\n",
    "#   - Filter by columns\n",
    "#     - `LEADS_SCREENING_VISIT` == \"sc\"\n",
    "#   - Join on columns\n",
    "#     - `LEADS_ID` -> `subject_id`\n",
    "#   - Include columns\n",
    "#     - `C2VISITYR`\n",
    "#     - `C2VISITMO`\n",
    "#     - `C2VISITDAY`\n",
    "#     - `CDRGLOB` -> `cdr_global_baseline`\n",
    "#     - `CDRSUM` -> `cdr_sb_baseline`\n",
    "#   - Add columns\n",
    "#     - `cdr_date`\n",
    "# !!----------------------------------!!\n",
    "# Load the dataframe\n",
    "aux[\"prelimdx\"] = pd.read_csv(\n",
    "    op.join(atri_dir, \"leads_codebook_study_data_prelimdx.csv\")\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "aux[\"\"] = aux[\"\"].rename(columns={})\n",
    "\n",
    "# Map integer values to string labels\n",
    "aux[\"\"][\"\"] = aux[\"\"][\"\"].map({})\n",
    "\n",
    "# Select needed columns\n",
    "keep_cols = [\"\"]\n",
    "aux[\"\"] = aux[\"\"][keep_cols]\n",
    "\n",
    "# Merge into the main subject dataframe\n",
    "subj_dat = subj_dat.merge(\n",
    "    aux[\"\"],\n",
    "    on=\"subject_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# - `atri/leads_codebook_study_data_pcadx.csv`\n",
    "#   - Filter by columns\n",
    "#       - `event_code` == \"sc\"\n",
    "#   - Join on columns\n",
    "#       - `subject_label` -> `subject_id`\n",
    "#   - Include columns\n",
    "#       - `pcaformal` -> `pca_formal`\n",
    "#         - 0 = \"Does not meet formal clinical diagnostic criteria for PCA\"\n",
    "#         - 1 = \"Meets formal clinical diagnostic criteria for PCA\"\n",
    "# !!----------------------------------!!\n",
    "# Load the dataframe\n",
    "aux[\"prelimdx\"] = pd.read_csv(\n",
    "    op.join(atri_dir, \"leads_codebook_study_data_prelimdx.csv\")\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "aux[\"\"] = aux[\"\"].rename(columns={})\n",
    "\n",
    "# Map integer values to string labels\n",
    "aux[\"\"][\"\"] = aux[\"\"][\"\"].map({})\n",
    "\n",
    "# Select needed columns\n",
    "keep_cols = [\"\"]\n",
    "aux[\"\"] = aux[\"\"][keep_cols]\n",
    "\n",
    "# Merge into the main subject dataframe\n",
    "subj_dat = subj_dat.merge(\n",
    "    aux[\"\"],\n",
    "    on=\"subject_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# - `atri/leads_codebook_study_data_ppadx.csv`\n",
    "#   - Filter by columns\n",
    "#       - `event_code` == \"sc\"\n",
    "#   - Join on columns\n",
    "#       - `subject_label` -> `subject_id`\n",
    "#   - Include columns\n",
    "#       - `lvppaformal` -> `lvppa_formal`\n",
    "#         - 0 = \"Does not meet formal clinical diagnostic criteria for lvPPA\"\n",
    "#         - 1 = \"Meets formal clinical diagnostic criteria for lvPPA\"\n",
    "# !!----------------------------------!!\n",
    "# Load the dataframe\n",
    "aux[\"prelimdx\"] = pd.read_csv(\n",
    "    op.join(atri_dir, \"leads_codebook_study_data_prelimdx.csv\")\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "aux[\"\"] = aux[\"\"].rename(columns={})\n",
    "\n",
    "# Map integer values to string labels\n",
    "aux[\"\"][\"\"] = aux[\"\"][\"\"].map({})\n",
    "\n",
    "# Select needed columns\n",
    "keep_cols = [\"\"]\n",
    "aux[\"\"] = aux[\"\"][keep_cols]\n",
    "\n",
    "# Merge into the main subject dataframe\n",
    "subj_dat = subj_dat.merge(\n",
    "    aux[\"\"],\n",
    "    on=\"subject_id\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APOE genotype\n",
    "\n",
    "Determine each participant's APOE genotype\n",
    "\n",
    "- `loni/Biospecimen_Analysis_Results*.csv`\n",
    "  - Join on columns\n",
    "    - `SUBJECT_CODE` -> `subject_id`\n",
    "  - Filter on columns\n",
    "    - `TESTNAME` == \"APOE Genotype\"\n",
    "  - Include columns\n",
    "    - `TESTVALUE` -> `apoe_genotype`\n",
    "  - Add columns\n",
    "    - `apoe4_alleles`\n",
    "      - 0\n",
    "      - 1\n",
    "      - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - `loni/Biospecimen_Analysis_Results*.csv`\n",
    "#   - Join on columns\n",
    "#     - `SUBJECT_CODE` -> `subject_id`\n",
    "#   - Filter on columns\n",
    "#     - `TESTNAME` == \"APOE Genotype\"\n",
    "#   - Include columns\n",
    "#     - `TESTVALUE` -> `apoe_genotype`\n",
    "#   - Add columns\n",
    "#     - `apoe4_alleles`\n",
    "#       - 0\n",
    "#       - 1\n",
    "#       - 2\n",
    "# !!----------------------------------!!\n",
    "# Load the dataframe\n",
    "aux[\"\"] = pd.read_csv(op.join(atri_dir, \"\"))\n",
    "\n",
    "# Rename columns\n",
    "aux[\"\"] = aux[\"\"].rename(columns={})\n",
    "\n",
    "# Map integer values to string labels\n",
    "aux[\"\"][\"\"] = aux[\"\"][\"\"].map({})\n",
    "\n",
    "# Select needed columns\n",
    "keep_cols = [\"\"]\n",
    "aux[\"\"] = aux[\"\"][keep_cols]\n",
    "\n",
    "# Merge into the main subject dataframe\n",
    "subj_dat = subj_dat.merge(\n",
    "    aux[\"\"],\n",
    "    on=\"subject_id\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anti-amyloid treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!----------------------------------!!\n",
    "# Load the dataframe\n",
    "aux[\"\"] = pd.read_csv(op.join(atri_dir, \"\"))\n",
    "\n",
    "# Rename columns\n",
    "aux[\"\"] = aux[\"\"].rename(columns={})\n",
    "\n",
    "# Map integer values to string labels\n",
    "aux[\"\"][\"\"] = aux[\"\"][\"\"].map({})\n",
    "\n",
    "# Select needed columns\n",
    "keep_cols = [\"\"]\n",
    "aux[\"\"] = aux[\"\"][keep_cols]\n",
    "\n",
    "# Merge into the main subject dataframe\n",
    "subj_dat = subj_dat.merge(\n",
    "    aux[\"\"],\n",
    "    on=\"subject_id\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quarterly report files\n",
    "\n",
    "Create dataframes for each PET tracer that will be uploaded to LONI with\n",
    "each LEADS quarterly report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_date(report_period):\n",
    "    \"\"\"Return the last date for inclusion in the current report period.\n",
    "\n",
    "    LEADS PET data are reported at a one-quarter lag, so the stop date\n",
    "    should match the end of the previous quarter.\n",
    "    \"\"\"\n",
    "    this_year, this_quarter = report_period.split(\"-\")\n",
    "    this_year = int(this_year)\n",
    "    this_quarter = int(this_quarter[1])\n",
    "\n",
    "    if this_quarter == 1:\n",
    "        stop_year = this_year - 1\n",
    "        stop_month = 12\n",
    "        stop_day = 31\n",
    "    elif this_quarter == 2:\n",
    "        stop_year = this_year\n",
    "        stop_month = 3\n",
    "        stop_day = 31\n",
    "    elif this_quarter == 3:\n",
    "        stop_year = this_year\n",
    "        stop_month = 6\n",
    "        stop_day = 30\n",
    "    elif this_quarter == 4:\n",
    "        stop_year = this_year\n",
    "        stop_month = 9\n",
    "        stop_day = 30\n",
    "\n",
    "    stop_date = pd.Timestamp(year=stop_year, month=stop_month, day=stop_day)\n",
    "    return stop_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retained 928 FBB scans from 595 subjects\n",
      "FBB: (928, 261)\n",
      "Retained 896 FTP scans from 585 subjects\n",
      "FTP: (896, 258)\n",
      "Retained 154 FDG scans from 154 subjects\n",
      "FDG: (154, 254)\n"
     ]
    }
   ],
   "source": [
    "# Define the current report period\n",
    "report_period = \"2024-Q2\"\n",
    "qrep_dat = {}\n",
    "\n",
    "for tracer in pets:\n",
    "    # Merge dataframes that will be used in the quarterly reports\n",
    "    qrep_dat[tracer] = pets[tracer].copy()\n",
    "    qrep_dat[tracer] = qrep_dat[tracer].merge(\n",
    "        ref_region_dat[tracer], on=[\"subject_id\", \"pet_date\"], how=\"left\"\n",
    "    )\n",
    "    if tracer == \"fbb\":\n",
    "        qrep_dat[tracer] = qrep_dat[tracer].merge(\n",
    "            screening, on=\"subject_id\", how=\"left\"\n",
    "        )\n",
    "        qrep_dat[tracer] = qrep_dat[tracer].merge(\n",
    "            centiloid_dat, on=[\"subject_id\", \"pet_date\"], how=\"left\"\n",
    "        )\n",
    "    else:\n",
    "        qrep_dat[tracer] = qrep_dat[tracer].merge(\n",
    "            screening[[\"subject_id\", \"CohortAssgn\"]], on=\"subject_id\", how=\"left\"\n",
    "        )\n",
    "    qrep_dat[tracer] = qrep_dat[tracer].merge(\n",
    "        roi_dat[tracer], on=[\"subject_id\", \"pet_date\"], how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Select scans that passed QC\n",
    "    qrep_dat[tracer] = qrep_dat[tracer].query(\"(qc_pass==1)\").reset_index(drop=True)\n",
    "\n",
    "    # Convert PET date to datetime\n",
    "    qrep_dat[tracer][\"pet_date\"] = pd.to_datetime(qrep_dat[tracer][\"pet_date\"])\n",
    "\n",
    "    # Remove scans from the current quarter onward\n",
    "    stop_date = get_stop_date(report_period)\n",
    "    qrep_dat[tracer] = (\n",
    "        qrep_dat[tracer].query(\"(pet_date <= @stop_date)\").reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Sort the data by subject_id and PET date\n",
    "    qrep_dat[tracer] = (\n",
    "        qrep_dat[tracer].sort_values([\"subject_id\", \"pet_date\"]).reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Convert PET date back to string\n",
    "    qrep_dat[tracer][\"pet_date\"] = qrep_dat[tracer][\"pet_date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Print final dataframe shape\n",
    "    n_scans = len(qrep_dat[tracer])\n",
    "    n_subjs = qrep_dat[tracer][\"subject_id\"].nunique()\n",
    "    print(f\"Retained {n_scans:,} {tracer.upper()} scans from {n_subjs:,} subjects\")\n",
    "    print(f\"{tracer.upper()}: {qrep_dat[tracer].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBB: (928, 253)\n"
     ]
    }
   ],
   "source": [
    "tracer = \"fbb\"\n",
    "save_output = True\n",
    "overwrite = False\n",
    "qreport_files = {}\n",
    "today = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_cols = [\n",
    "    \"tracer\",\n",
    "    \"pet_scan_number\",\n",
    "    \"n_pet_scans\",\n",
    "    \"days_from_baseline_pet\",\n",
    "    \"days_from_last_pet\",\n",
    "    \"pet_res\",\n",
    "    \"mri_date\",\n",
    "    \"mri_image_id\",\n",
    "    \"days_mri_to_pet\",\n",
    "    \"abs_days_mri_to_pet\",\n",
    "    \"pet_proc_dir\",\n",
    "    \"pet_qc_pass\",\n",
    "    \"native_pet_ok\",\n",
    "    \"pet_to_mri_coreg_ok\",\n",
    "    \"wcbl_mask_ok\",\n",
    "    \"erodedwm+bstem_masks_ok\",\n",
    "    \"warped_pet_ok\",\n",
    "    \"pet_qc_notes\",\n",
    "    \"mri_qc_notes\",\n",
    "    \"qc_pass\",\n",
    "    \"centiloids_compwm\",\n",
    "    \"brainstem_MRIBASED_SUVR\",\n",
    "    \"eroded_subcortwm_MRIBASED_SUVR\",\n",
    "    \"cortex_desikan_MRIBASED_SUVR\",\n",
    "    \"brainstem_ClustSize\",\n",
    "    \"eroded_subcortwm_ClustSize\",\n",
    "    \"amyloid_cortical_summary_ClustSize\",\n",
    "    \"cortex_desikan_ClustSize\",\n",
    "]\n",
    "qrep_dat[tracer] = qrep_dat[tracer].drop(columns=drop_cols)\n",
    "\n",
    "# Rename columns\n",
    "qrep_dat[tracer] = qrep_dat[tracer].rename(\n",
    "    columns={\n",
    "        \"subject_id\": \"ID\",\n",
    "        \"pet_date\": \"FBBPET_Date\",\n",
    "        \"pet_image_id\": \"ImageID\",\n",
    "        \"ScalingFactor_wcbl\": \"ScalingFactor_WholeCereb\",\n",
    "        \"ScalingFactor_compwm\": \"ScalingFactor_CompositeWM\",\n",
    "        \"centiloids_wcbl\": \"MRIBASED_Composite_Centiloids\",\n",
    "        \"wcbl_MRIBASED_SUVR\": \"WholeCerebellum_MRIBASED_SUVR\",\n",
    "        \"amyloid_cortical_summary_MRIBASED_SUVR\": \"MRIBASED_Composite_SUVR\",\n",
    "        \"3rd_Ventricle_MRIBASED_SUVR\": \"Third_Ventricle_MRIBASED_SUVR\",\n",
    "        \"4th_Ventricle_MRIBASED_SUVR\": \"Fourth_Ventricle_MRIBASED_SUVR\",\n",
    "        \"wcbl_ClustSize\": \"WholeCerebellum_ClustSize\",\n",
    "        \"3rd_Ventricle_ClustSize\": \"Third_Ventricle_ClustSize\",\n",
    "        \"4th_Ventricle_ClustSize\": \"Fourth_Ventricle_ClustSize\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add empty columns\n",
    "add_cols = [\n",
    "    \"ACC_PCC_MRIBASED_SUVR\",\n",
    "    \"Frontal_MRIBASED_SUVR\",\n",
    "    \"Temporal_MRIBASED_SUVR\",\n",
    "    \"Parietal_MRIBASED_SUVR\",\n",
    "    \"CompositeWM_MRIBASED_SUVR\",\n",
    "    \"Left_vessel_MRIBASED_SUVR\",\n",
    "    \"Right_vessel_MRIBASED_SUVR\",\n",
    "    \"Fifth_Ventricle_MRIBASED_SUVR\",\n",
    "    \"non_WM_hypointensities_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_unknown_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_unknown_MRIBASED_SUVR\",\n",
    "    \"ScalingFactor_WholeCereb_ClustSize\",\n",
    "    \"ScalingFactor_CompositeWM_ClustSize\",\n",
    "    \"ACC_PCC_ClustSize\",\n",
    "    \"Frontal_ClustSize\",\n",
    "    \"Temporal_ClustSize\",\n",
    "    \"Parietal_ClustSize\",\n",
    "    \"CompositeWM_ClustSize\",\n",
    "    \"Left_vessel_ClustSize\",\n",
    "    \"Right_vessel_ClustSize\",\n",
    "    \"Fifth_Ventricle_ClustSize\",\n",
    "    \"non_WM_hypointensities_ClustSize\",\n",
    "    \"ctx_lh_unknown_ClustSize\",\n",
    "    \"ctx_rh_unknown_ClustSize\",\n",
    "]\n",
    "for col in add_cols:\n",
    "    qrep_dat[tracer][col] = np.nan\n",
    "\n",
    "\n",
    "# Nullify columns associated with the longitudinal reference region\n",
    "na_cols = [\n",
    "    \"ScalingFactor_CompositeWM\",\n",
    "]\n",
    "for col in na_cols:\n",
    "    qrep_dat[tracer][col] = np.nan\n",
    "\n",
    "# Reorder columns\n",
    "cols_in_order = [\n",
    "    \"ID\",\n",
    "    \"FBBPET_Date\",\n",
    "    \"ImageID\",\n",
    "    \"Screening_PETONLY_Composite_SUVR\",\n",
    "    \"Screening_PETONLY_AmyPos_Quantification_1p18\",\n",
    "    \"Screening_PETONLY_VisualRead\",\n",
    "    \"Screening_PETONLY_Disagreement\",\n",
    "    \"Screening_PETONLY_Final_Read\",\n",
    "    \"CohortAssgn\",\n",
    "    \"ScalingFactor_WholeCereb\",\n",
    "    \"ScalingFactor_CompositeWM\",\n",
    "    \"MRIBASED_Composite_SUVR\",\n",
    "    \"MRIBASED_Composite_Centiloids\",\n",
    "    \"ACC_PCC_MRIBASED_SUVR\",\n",
    "    \"Frontal_MRIBASED_SUVR\",\n",
    "    \"Temporal_MRIBASED_SUVR\",\n",
    "    \"Parietal_MRIBASED_SUVR\",\n",
    "    \"WholeCerebellum_MRIBASED_SUVR\",\n",
    "    \"CompositeWM_MRIBASED_SUVR\",\n",
    "    \"Left_Cerebral_White_Matter_MRIBASED_SUVR\",\n",
    "    \"Left_Lateral_Ventricle_MRIBASED_SUVR\",\n",
    "    \"Left_Inf_Lat_Vent_MRIBASED_SUVR\",\n",
    "    \"Left_Cerebellum_White_Matter_MRIBASED_SUVR\",\n",
    "    \"Left_Cerebellum_Cortex_MRIBASED_SUVR\",\n",
    "    \"Left_Thalamus_Proper_MRIBASED_SUVR\",\n",
    "    \"Left_Caudate_MRIBASED_SUVR\",\n",
    "    \"Left_Putamen_MRIBASED_SUVR\",\n",
    "    \"Left_Pallidum_MRIBASED_SUVR\",\n",
    "    \"Third_Ventricle_MRIBASED_SUVR\",\n",
    "    \"Fourth_Ventricle_MRIBASED_SUVR\",\n",
    "    \"Brain_Stem_MRIBASED_SUVR\",\n",
    "    \"Left_Hippocampus_MRIBASED_SUVR\",\n",
    "    \"Left_Amygdala_MRIBASED_SUVR\",\n",
    "    \"CSF_MRIBASED_SUVR\",\n",
    "    \"Left_Accumbens_area_MRIBASED_SUVR\",\n",
    "    \"Left_VentralDC_MRIBASED_SUVR\",\n",
    "    \"Left_vessel_MRIBASED_SUVR\",\n",
    "    \"Left_choroid_plexus_MRIBASED_SUVR\",\n",
    "    \"Right_Cerebral_White_Matter_MRIBASED_SUVR\",\n",
    "    \"Right_Lateral_Ventricle_MRIBASED_SUVR\",\n",
    "    \"Right_Inf_Lat_Vent_MRIBASED_SUVR\",\n",
    "    \"Right_Cerebellum_White_Matter_MRIBASED_SUVR\",\n",
    "    \"Right_Cerebellum_Cortex_MRIBASED_SUVR\",\n",
    "    \"Right_Thalamus_Proper_MRIBASED_SUVR\",\n",
    "    \"Right_Caudate_MRIBASED_SUVR\",\n",
    "    \"Right_Putamen_MRIBASED_SUVR\",\n",
    "    \"Right_Pallidum_MRIBASED_SUVR\",\n",
    "    \"Right_Hippocampus_MRIBASED_SUVR\",\n",
    "    \"Right_Amygdala_MRIBASED_SUVR\",\n",
    "    \"Right_Accumbens_area_MRIBASED_SUVR\",\n",
    "    \"Right_VentralDC_MRIBASED_SUVR\",\n",
    "    \"Right_vessel_MRIBASED_SUVR\",\n",
    "    \"Right_choroid_plexus_MRIBASED_SUVR\",\n",
    "    \"Fifth_Ventricle_MRIBASED_SUVR\",\n",
    "    \"WM_hypointensities_MRIBASED_SUVR\",\n",
    "    \"non_WM_hypointensities_MRIBASED_SUVR\",\n",
    "    \"Optic_Chiasm_MRIBASED_SUVR\",\n",
    "    \"CC_Posterior_MRIBASED_SUVR\",\n",
    "    \"CC_Mid_Posterior_MRIBASED_SUVR\",\n",
    "    \"CC_Central_MRIBASED_SUVR\",\n",
    "    \"CC_Mid_Anterior_MRIBASED_SUVR\",\n",
    "    \"CC_Anterior_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_unknown_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_bankssts_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_caudalanteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_caudalmiddlefrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_cuneus_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_entorhinal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_fusiform_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_inferiorparietal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_inferiortemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_isthmuscingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_lateraloccipital_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_lateralorbitofrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_lingual_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_medialorbitofrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_middletemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_parahippocampal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_paracentral_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_parsopercularis_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_parsorbitalis_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_parstriangularis_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_pericalcarine_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_postcentral_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_posteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_precentral_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_precuneus_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_rostralanteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_rostralmiddlefrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_superiorfrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_superiorparietal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_superiortemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_supramarginal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_frontalpole_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_temporalpole_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_transversetemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_insula_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_unknown_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_bankssts_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_caudalanteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_caudalmiddlefrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_cuneus_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_entorhinal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_fusiform_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_inferiorparietal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_inferiortemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_isthmuscingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_lateraloccipital_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_lateralorbitofrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_lingual_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_medialorbitofrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_middletemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_parahippocampal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_paracentral_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_parsopercularis_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_parsorbitalis_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_parstriangularis_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_pericalcarine_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_postcentral_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_posteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_precentral_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_precuneus_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_rostralanteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_rostralmiddlefrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_superiorfrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_superiorparietal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_superiortemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_supramarginal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_frontalpole_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_temporalpole_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_transversetemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_insula_MRIBASED_SUVR\",\n",
    "    \"ScalingFactor_WholeCereb_ClustSize\",\n",
    "    \"ScalingFactor_CompositeWM_ClustSize\",\n",
    "    \"ACC_PCC_ClustSize\",\n",
    "    \"Frontal_ClustSize\",\n",
    "    \"Temporal_ClustSize\",\n",
    "    \"Parietal_ClustSize\",\n",
    "    \"WholeCerebellum_ClustSize\",\n",
    "    \"CompositeWM_ClustSize\",\n",
    "    \"Left_Cerebral_White_Matter_ClustSize\",\n",
    "    \"Left_Lateral_Ventricle_ClustSize\",\n",
    "    \"Left_Inf_Lat_Vent_ClustSize\",\n",
    "    \"Left_Cerebellum_White_Matter_ClustSize\",\n",
    "    \"Left_Cerebellum_Cortex_ClustSize\",\n",
    "    \"Left_Thalamus_Proper_ClustSize\",\n",
    "    \"Left_Caudate_ClustSize\",\n",
    "    \"Left_Putamen_ClustSize\",\n",
    "    \"Left_Pallidum_ClustSize\",\n",
    "    \"Third_Ventricle_ClustSize\",\n",
    "    \"Fourth_Ventricle_ClustSize\",\n",
    "    \"Brain_Stem_ClustSize\",\n",
    "    \"Left_Hippocampus_ClustSize\",\n",
    "    \"Left_Amygdala_ClustSize\",\n",
    "    \"CSF_ClustSize\",\n",
    "    \"Left_Accumbens_area_ClustSize\",\n",
    "    \"Left_VentralDC_ClustSize\",\n",
    "    \"Left_vessel_ClustSize\",\n",
    "    \"Left_choroid_plexus_ClustSize\",\n",
    "    \"Right_Cerebral_White_Matter_ClustSize\",\n",
    "    \"Right_Lateral_Ventricle_ClustSize\",\n",
    "    \"Right_Inf_Lat_Vent_ClustSize\",\n",
    "    \"Right_Cerebellum_White_Matter_ClustSize\",\n",
    "    \"Right_Cerebellum_Cortex_ClustSize\",\n",
    "    \"Right_Thalamus_Proper_ClustSize\",\n",
    "    \"Right_Caudate_ClustSize\",\n",
    "    \"Right_Putamen_ClustSize\",\n",
    "    \"Right_Pallidum_ClustSize\",\n",
    "    \"Right_Hippocampus_ClustSize\",\n",
    "    \"Right_Amygdala_ClustSize\",\n",
    "    \"Right_Accumbens_area_ClustSize\",\n",
    "    \"Right_VentralDC_ClustSize\",\n",
    "    \"Right_vessel_ClustSize\",\n",
    "    \"Right_choroid_plexus_ClustSize\",\n",
    "    \"Fifth_Ventricle_ClustSize\",\n",
    "    \"WM_hypointensities_ClustSize\",\n",
    "    \"non_WM_hypointensities_ClustSize\",\n",
    "    \"Optic_Chiasm_ClustSize\",\n",
    "    \"CC_Posterior_ClustSize\",\n",
    "    \"CC_Mid_Posterior_ClustSize\",\n",
    "    \"CC_Central_ClustSize\",\n",
    "    \"CC_Mid_Anterior_ClustSize\",\n",
    "    \"CC_Anterior_ClustSize\",\n",
    "    \"ctx_lh_unknown_ClustSize\",\n",
    "    \"ctx_lh_bankssts_ClustSize\",\n",
    "    \"ctx_lh_caudalanteriorcingulate_ClustSize\",\n",
    "    \"ctx_lh_caudalmiddlefrontal_ClustSize\",\n",
    "    \"ctx_lh_cuneus_ClustSize\",\n",
    "    \"ctx_lh_entorhinal_ClustSize\",\n",
    "    \"ctx_lh_fusiform_ClustSize\",\n",
    "    \"ctx_lh_inferiorparietal_ClustSize\",\n",
    "    \"ctx_lh_inferiortemporal_ClustSize\",\n",
    "    \"ctx_lh_isthmuscingulate_ClustSize\",\n",
    "    \"ctx_lh_lateraloccipital_ClustSize\",\n",
    "    \"ctx_lh_lateralorbitofrontal_ClustSize\",\n",
    "    \"ctx_lh_lingual_ClustSize\",\n",
    "    \"ctx_lh_medialorbitofrontal_ClustSize\",\n",
    "    \"ctx_lh_middletemporal_ClustSize\",\n",
    "    \"ctx_lh_parahippocampal_ClustSize\",\n",
    "    \"ctx_lh_paracentral_ClustSize\",\n",
    "    \"ctx_lh_parsopercularis_ClustSize\",\n",
    "    \"ctx_lh_parsorbitalis_ClustSize\",\n",
    "    \"ctx_lh_parstriangularis_ClustSize\",\n",
    "    \"ctx_lh_pericalcarine_ClustSize\",\n",
    "    \"ctx_lh_postcentral_ClustSize\",\n",
    "    \"ctx_lh_posteriorcingulate_ClustSize\",\n",
    "    \"ctx_lh_precentral_ClustSize\",\n",
    "    \"ctx_lh_precuneus_ClustSize\",\n",
    "    \"ctx_lh_rostralanteriorcingulate_ClustSize\",\n",
    "    \"ctx_lh_rostralmiddlefrontal_ClustSize\",\n",
    "    \"ctx_lh_superiorfrontal_ClustSize\",\n",
    "    \"ctx_lh_superiorparietal_ClustSize\",\n",
    "    \"ctx_lh_superiortemporal_ClustSize\",\n",
    "    \"ctx_lh_supramarginal_ClustSize\",\n",
    "    \"ctx_lh_frontalpole_ClustSize\",\n",
    "    \"ctx_lh_temporalpole_ClustSize\",\n",
    "    \"ctx_lh_transversetemporal_ClustSize\",\n",
    "    \"ctx_lh_insula_ClustSize\",\n",
    "    \"ctx_rh_unknown_ClustSize\",\n",
    "    \"ctx_rh_bankssts_ClustSize\",\n",
    "    \"ctx_rh_caudalanteriorcingulate_ClustSize\",\n",
    "    \"ctx_rh_caudalmiddlefrontal_ClustSize\",\n",
    "    \"ctx_rh_cuneus_ClustSize\",\n",
    "    \"ctx_rh_entorhinal_ClustSize\",\n",
    "    \"ctx_rh_fusiform_ClustSize\",\n",
    "    \"ctx_rh_inferiorparietal_ClustSize\",\n",
    "    \"ctx_rh_inferiortemporal_ClustSize\",\n",
    "    \"ctx_rh_isthmuscingulate_ClustSize\",\n",
    "    \"ctx_rh_lateraloccipital_ClustSize\",\n",
    "    \"ctx_rh_lateralorbitofrontal_ClustSize\",\n",
    "    \"ctx_rh_lingual_ClustSize\",\n",
    "    \"ctx_rh_medialorbitofrontal_ClustSize\",\n",
    "    \"ctx_rh_middletemporal_ClustSize\",\n",
    "    \"ctx_rh_parahippocampal_ClustSize\",\n",
    "    \"ctx_rh_paracentral_ClustSize\",\n",
    "    \"ctx_rh_parsopercularis_ClustSize\",\n",
    "    \"ctx_rh_parsorbitalis_ClustSize\",\n",
    "    \"ctx_rh_parstriangularis_ClustSize\",\n",
    "    \"ctx_rh_pericalcarine_ClustSize\",\n",
    "    \"ctx_rh_postcentral_ClustSize\",\n",
    "    \"ctx_rh_posteriorcingulate_ClustSize\",\n",
    "    \"ctx_rh_precentral_ClustSize\",\n",
    "    \"ctx_rh_precuneus_ClustSize\",\n",
    "    \"ctx_rh_rostralanteriorcingulate_ClustSize\",\n",
    "    \"ctx_rh_rostralmiddlefrontal_ClustSize\",\n",
    "    \"ctx_rh_superiorfrontal_ClustSize\",\n",
    "    \"ctx_rh_superiorparietal_ClustSize\",\n",
    "    \"ctx_rh_superiortemporal_ClustSize\",\n",
    "    \"ctx_rh_supramarginal_ClustSize\",\n",
    "    \"ctx_rh_frontalpole_ClustSize\",\n",
    "    \"ctx_rh_temporalpole_ClustSize\",\n",
    "    \"ctx_rh_transversetemporal_ClustSize\",\n",
    "    \"ctx_rh_insula_ClustSize\",\n",
    "]\n",
    "qrep_dat[tracer] = qrep_dat[tracer][cols_in_order]\n",
    "\n",
    "# Save the output dataframe\n",
    "qreport_files[tracer] = op.join(\n",
    "    qreport_dir,\n",
    "    f\"LEADS-PETCore-quarterly-report_{report_period}_{tracer.upper()}-ROI-means_{today}.csv\",\n",
    ")\n",
    "if save_output:\n",
    "    if overwrite or not op.isfile(qreport_files[tracer]):\n",
    "        qrep_dat[tracer].to_csv(qreport_files[tracer], index=False)\n",
    "        print(f\"Saved {qreport_files[tracer]}\")\n",
    "\n",
    "print(f\"{tracer.upper()}: {qrep_dat[tracer].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTP: (896, 247)\n"
     ]
    }
   ],
   "source": [
    "tracer = \"ftp\"\n",
    "save_output = True\n",
    "overwrite = False\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_cols = [\n",
    "    \"tracer\",\n",
    "    \"pet_scan_number\",\n",
    "    \"n_pet_scans\",\n",
    "    \"days_from_baseline_pet\",\n",
    "    \"days_from_last_pet\",\n",
    "    \"pet_res\",\n",
    "    \"mri_date\",\n",
    "    \"mri_image_id\",\n",
    "    \"days_mri_to_pet\",\n",
    "    \"abs_days_mri_to_pet\",\n",
    "    \"pet_proc_dir\",\n",
    "    \"pet_qc_pass\",\n",
    "    \"native_pet_ok\",\n",
    "    \"pet_to_mri_coreg_ok\",\n",
    "    \"infcblgm_mask_ok\",\n",
    "    \"erodedwm_mask_ok\",\n",
    "    \"warped_pet_ok\",\n",
    "    \"pet_qc_notes\",\n",
    "    \"mri_qc_pass\",\n",
    "    \"native_nu_rating\",\n",
    "    \"aparc+aseg_rating\",\n",
    "    \"warped_nu_ok\",\n",
    "    \"mri_qc_notes\",\n",
    "    \"qc_pass\",\n",
    "    \"infcblgm_MRIBASED_SUVR\",\n",
    "    \"mtl_no_hippocampus_MRIBASED_SUVR\",\n",
    "    \"basolateral_temporal_MRIBASED_SUVR\",\n",
    "    \"temporoparietal_MRIBASED_SUVR\",\n",
    "    \"cortex_desikan_MRIBASED_SUVR\",\n",
    "    \"mtl_no_hippocampus_ClustSize\",\n",
    "    \"basolateral_temporal_ClustSize\",\n",
    "    \"temporoparietal_ClustSize\",\n",
    "    \"cortex_desikan_ClustSize\",\n",
    "]\n",
    "qrep_dat[tracer] = qrep_dat[tracer].drop(columns=drop_cols)\n",
    "\n",
    "# Rename columns\n",
    "qrep_dat[tracer] = qrep_dat[tracer].rename(\n",
    "    columns={\n",
    "        \"subject_id\": \"ID\",\n",
    "        \"pet_date\": \"FTPPET_Date\",\n",
    "        \"pet_image_id\": \"ImageID\",\n",
    "        \"ScalingFactor_infcblgm\": \"ScalingFactor_InfCerebGray\",\n",
    "        \"ScalingFactor_eroded\": \"ScalingFactor_ErodedWM\",\n",
    "        \"eroded_subcortwm_MRIBASED_SUVR\": \"ErodedWM_MRIBASED_SUVR\",\n",
    "        \"meta_temporal_MRIBASED_SUVR\": \"MetaROI_MRIBASED_SUVR\",\n",
    "        \"3rd_Ventricle_MRIBASED_SUVR\": \"Third_Ventricle_MRIBASED_SUVR\",\n",
    "        \"4th_Ventricle_MRIBASED_SUVR\": \"Fourth_Ventricle_MRIBASED_SUVR\",\n",
    "        \"eroded_subcortwm_ClustSize\": \"ScalingFactor_ErodedWM_ClustSize\",\n",
    "        \"infcblgm_ClustSize\": \"ScalingFactor_InfCerebGray_ClustSize\",\n",
    "        \"meta_temporal_ClustSize\": \"MetaROI_ClustSize\",\n",
    "        \"3rd_Ventricle_ClustSize\": \"Third_Ventricle_ClustSize\",\n",
    "        \"4th_Ventricle_ClustSize\": \"Fourth_Ventricle_ClustSize\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add empty columns\n",
    "add_cols = [\n",
    "    \"Assigned_MRIBASED_MetaROI_ADNIcutoff_1p2\",\n",
    "    \"Braak_1_MRIBASED_SUVR\",\n",
    "    \"Braak_12_MRIBASED_SUVR\",\n",
    "    \"Braak_34_MRIBASED_SUVR\",\n",
    "    \"Braak_56_MRIBASED_SUVR\",\n",
    "    \"Left_vessel_MRIBASED_SUVR\",\n",
    "    \"Right_vessel_MRIBASED_SUVR\",\n",
    "    \"Fifth_Ventricle_MRIBASED_SUVR\",\n",
    "    \"non_WM_hypointensities_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_unknown_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_unknown_MRIBASED_SUVR\",\n",
    "    \"Braak_1_ClustSize\",\n",
    "    \"Braak_12_ClustSize\",\n",
    "    \"Braak_34_ClustSize\",\n",
    "    \"Braak_56_ClustSize\",\n",
    "    \"ErodedWM_ClustSize\",\n",
    "    \"Left_vessel_ClustSize\",\n",
    "    \"Right_vessel_ClustSize\",\n",
    "    \"Fifth_Ventricle_ClustSize\",\n",
    "    \"non_WM_hypointensities_ClustSize\",\n",
    "    \"ctx_lh_unknown_ClustSize\",\n",
    "    \"ctx_rh_unknown_ClustSize\",\n",
    "]\n",
    "for col in add_cols:\n",
    "    qrep_dat[tracer][col] = np.nan\n",
    "\n",
    "\n",
    "# Nullify columns associated with the longitudinal reference region\n",
    "na_cols = [\n",
    "    \"ScalingFactor_ErodedWM\",\n",
    "    \"ErodedWM_MRIBASED_SUVR\",\n",
    "    \"ScalingFactor_ErodedWM_ClustSize\",\n",
    "]\n",
    "for col in na_cols:\n",
    "    qrep_dat[tracer][col] = np.nan\n",
    "\n",
    "# Reorder columns\n",
    "cols_in_order = [\n",
    "    \"ID\",\n",
    "    \"FTPPET_Date\",\n",
    "    \"ImageID\",\n",
    "    \"CohortAssgn\",\n",
    "    \"ScalingFactor_InfCerebGray\",\n",
    "    \"ScalingFactor_ErodedWM\",\n",
    "    \"Assigned_MRIBASED_MetaROI_ADNIcutoff_1p2\",\n",
    "    \"MetaROI_MRIBASED_SUVR\",\n",
    "    \"Braak_1_MRIBASED_SUVR\",\n",
    "    \"Braak_12_MRIBASED_SUVR\",\n",
    "    \"Braak_34_MRIBASED_SUVR\",\n",
    "    \"Braak_56_MRIBASED_SUVR\",\n",
    "    \"ErodedWM_MRIBASED_SUVR\",\n",
    "    \"Left_Cerebral_White_Matter_MRIBASED_SUVR\",\n",
    "    \"Left_Lateral_Ventricle_MRIBASED_SUVR\",\n",
    "    \"Left_Inf_Lat_Vent_MRIBASED_SUVR\",\n",
    "    \"Left_Cerebellum_White_Matter_MRIBASED_SUVR\",\n",
    "    \"Left_Cerebellum_Cortex_MRIBASED_SUVR\",\n",
    "    \"Left_Thalamus_Proper_MRIBASED_SUVR\",\n",
    "    \"Left_Caudate_MRIBASED_SUVR\",\n",
    "    \"Left_Putamen_MRIBASED_SUVR\",\n",
    "    \"Left_Pallidum_MRIBASED_SUVR\",\n",
    "    \"Third_Ventricle_MRIBASED_SUVR\",\n",
    "    \"Fourth_Ventricle_MRIBASED_SUVR\",\n",
    "    \"Brain_Stem_MRIBASED_SUVR\",\n",
    "    \"Left_Hippocampus_MRIBASED_SUVR\",\n",
    "    \"Left_Amygdala_MRIBASED_SUVR\",\n",
    "    \"CSF_MRIBASED_SUVR\",\n",
    "    \"Left_Accumbens_area_MRIBASED_SUVR\",\n",
    "    \"Left_VentralDC_MRIBASED_SUVR\",\n",
    "    \"Left_vessel_MRIBASED_SUVR\",\n",
    "    \"Left_choroid_plexus_MRIBASED_SUVR\",\n",
    "    \"Right_Cerebral_White_Matter_MRIBASED_SUVR\",\n",
    "    \"Right_Lateral_Ventricle_MRIBASED_SUVR\",\n",
    "    \"Right_Inf_Lat_Vent_MRIBASED_SUVR\",\n",
    "    \"Right_Cerebellum_White_Matter_MRIBASED_SUVR\",\n",
    "    \"Right_Cerebellum_Cortex_MRIBASED_SUVR\",\n",
    "    \"Right_Thalamus_Proper_MRIBASED_SUVR\",\n",
    "    \"Right_Caudate_MRIBASED_SUVR\",\n",
    "    \"Right_Putamen_MRIBASED_SUVR\",\n",
    "    \"Right_Pallidum_MRIBASED_SUVR\",\n",
    "    \"Right_Hippocampus_MRIBASED_SUVR\",\n",
    "    \"Right_Amygdala_MRIBASED_SUVR\",\n",
    "    \"Right_Accumbens_area_MRIBASED_SUVR\",\n",
    "    \"Right_VentralDC_MRIBASED_SUVR\",\n",
    "    \"Right_vessel_MRIBASED_SUVR\",\n",
    "    \"Right_choroid_plexus_MRIBASED_SUVR\",\n",
    "    \"Fifth_Ventricle_MRIBASED_SUVR\",\n",
    "    \"WM_hypointensities_MRIBASED_SUVR\",\n",
    "    \"non_WM_hypointensities_MRIBASED_SUVR\",\n",
    "    \"Optic_Chiasm_MRIBASED_SUVR\",\n",
    "    \"CC_Posterior_MRIBASED_SUVR\",\n",
    "    \"CC_Mid_Posterior_MRIBASED_SUVR\",\n",
    "    \"CC_Central_MRIBASED_SUVR\",\n",
    "    \"CC_Mid_Anterior_MRIBASED_SUVR\",\n",
    "    \"CC_Anterior_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_unknown_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_bankssts_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_caudalanteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_caudalmiddlefrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_cuneus_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_entorhinal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_fusiform_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_inferiorparietal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_inferiortemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_isthmuscingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_lateraloccipital_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_lateralorbitofrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_lingual_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_medialorbitofrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_middletemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_parahippocampal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_paracentral_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_parsopercularis_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_parsorbitalis_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_parstriangularis_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_pericalcarine_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_postcentral_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_posteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_precentral_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_precuneus_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_rostralanteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_rostralmiddlefrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_superiorfrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_superiorparietal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_superiortemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_supramarginal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_frontalpole_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_temporalpole_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_transversetemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_insula_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_unknown_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_bankssts_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_caudalanteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_caudalmiddlefrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_cuneus_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_entorhinal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_fusiform_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_inferiorparietal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_inferiortemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_isthmuscingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_lateraloccipital_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_lateralorbitofrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_lingual_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_medialorbitofrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_middletemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_parahippocampal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_paracentral_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_parsopercularis_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_parsorbitalis_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_parstriangularis_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_pericalcarine_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_postcentral_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_posteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_precentral_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_precuneus_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_rostralanteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_rostralmiddlefrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_superiorfrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_superiorparietal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_superiortemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_supramarginal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_frontalpole_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_temporalpole_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_transversetemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_insula_MRIBASED_SUVR\",\n",
    "    \"ScalingFactor_InfCerebGray_ClustSize\",\n",
    "    \"ScalingFactor_ErodedWM_ClustSize\",\n",
    "    \"MetaROI_ClustSize\",\n",
    "    \"Braak_1_ClustSize\",\n",
    "    \"Braak_12_ClustSize\",\n",
    "    \"Braak_34_ClustSize\",\n",
    "    \"Braak_56_ClustSize\",\n",
    "    \"ErodedWM_ClustSize\",\n",
    "    \"Left_Cerebral_White_Matter_ClustSize\",\n",
    "    \"Left_Lateral_Ventricle_ClustSize\",\n",
    "    \"Left_Inf_Lat_Vent_ClustSize\",\n",
    "    \"Left_Cerebellum_White_Matter_ClustSize\",\n",
    "    \"Left_Cerebellum_Cortex_ClustSize\",\n",
    "    \"Left_Thalamus_Proper_ClustSize\",\n",
    "    \"Left_Caudate_ClustSize\",\n",
    "    \"Left_Putamen_ClustSize\",\n",
    "    \"Left_Pallidum_ClustSize\",\n",
    "    \"Third_Ventricle_ClustSize\",\n",
    "    \"Fourth_Ventricle_ClustSize\",\n",
    "    \"Brain_Stem_ClustSize\",\n",
    "    \"Left_Hippocampus_ClustSize\",\n",
    "    \"Left_Amygdala_ClustSize\",\n",
    "    \"CSF_ClustSize\",\n",
    "    \"Left_Accumbens_area_ClustSize\",\n",
    "    \"Left_VentralDC_ClustSize\",\n",
    "    \"Left_vessel_ClustSize\",\n",
    "    \"Left_choroid_plexus_ClustSize\",\n",
    "    \"Right_Cerebral_White_Matter_ClustSize\",\n",
    "    \"Right_Lateral_Ventricle_ClustSize\",\n",
    "    \"Right_Inf_Lat_Vent_ClustSize\",\n",
    "    \"Right_Cerebellum_White_Matter_ClustSize\",\n",
    "    \"Right_Cerebellum_Cortex_ClustSize\",\n",
    "    \"Right_Thalamus_Proper_ClustSize\",\n",
    "    \"Right_Caudate_ClustSize\",\n",
    "    \"Right_Putamen_ClustSize\",\n",
    "    \"Right_Pallidum_ClustSize\",\n",
    "    \"Right_Hippocampus_ClustSize\",\n",
    "    \"Right_Amygdala_ClustSize\",\n",
    "    \"Right_Accumbens_area_ClustSize\",\n",
    "    \"Right_VentralDC_ClustSize\",\n",
    "    \"Right_vessel_ClustSize\",\n",
    "    \"Right_choroid_plexus_ClustSize\",\n",
    "    \"Fifth_Ventricle_ClustSize\",\n",
    "    \"WM_hypointensities_ClustSize\",\n",
    "    \"non_WM_hypointensities_ClustSize\",\n",
    "    \"Optic_Chiasm_ClustSize\",\n",
    "    \"CC_Posterior_ClustSize\",\n",
    "    \"CC_Mid_Posterior_ClustSize\",\n",
    "    \"CC_Central_ClustSize\",\n",
    "    \"CC_Mid_Anterior_ClustSize\",\n",
    "    \"CC_Anterior_ClustSize\",\n",
    "    \"ctx_lh_unknown_ClustSize\",\n",
    "    \"ctx_lh_bankssts_ClustSize\",\n",
    "    \"ctx_lh_caudalanteriorcingulate_ClustSize\",\n",
    "    \"ctx_lh_caudalmiddlefrontal_ClustSize\",\n",
    "    \"ctx_lh_cuneus_ClustSize\",\n",
    "    \"ctx_lh_entorhinal_ClustSize\",\n",
    "    \"ctx_lh_fusiform_ClustSize\",\n",
    "    \"ctx_lh_inferiorparietal_ClustSize\",\n",
    "    \"ctx_lh_inferiortemporal_ClustSize\",\n",
    "    \"ctx_lh_isthmuscingulate_ClustSize\",\n",
    "    \"ctx_lh_lateraloccipital_ClustSize\",\n",
    "    \"ctx_lh_lateralorbitofrontal_ClustSize\",\n",
    "    \"ctx_lh_lingual_ClustSize\",\n",
    "    \"ctx_lh_medialorbitofrontal_ClustSize\",\n",
    "    \"ctx_lh_middletemporal_ClustSize\",\n",
    "    \"ctx_lh_parahippocampal_ClustSize\",\n",
    "    \"ctx_lh_paracentral_ClustSize\",\n",
    "    \"ctx_lh_parsopercularis_ClustSize\",\n",
    "    \"ctx_lh_parsorbitalis_ClustSize\",\n",
    "    \"ctx_lh_parstriangularis_ClustSize\",\n",
    "    \"ctx_lh_pericalcarine_ClustSize\",\n",
    "    \"ctx_lh_postcentral_ClustSize\",\n",
    "    \"ctx_lh_posteriorcingulate_ClustSize\",\n",
    "    \"ctx_lh_precentral_ClustSize\",\n",
    "    \"ctx_lh_precuneus_ClustSize\",\n",
    "    \"ctx_lh_rostralanteriorcingulate_ClustSize\",\n",
    "    \"ctx_lh_rostralmiddlefrontal_ClustSize\",\n",
    "    \"ctx_lh_superiorfrontal_ClustSize\",\n",
    "    \"ctx_lh_superiorparietal_ClustSize\",\n",
    "    \"ctx_lh_superiortemporal_ClustSize\",\n",
    "    \"ctx_lh_supramarginal_ClustSize\",\n",
    "    \"ctx_lh_frontalpole_ClustSize\",\n",
    "    \"ctx_lh_temporalpole_ClustSize\",\n",
    "    \"ctx_lh_transversetemporal_ClustSize\",\n",
    "    \"ctx_lh_insula_ClustSize\",\n",
    "    \"ctx_rh_unknown_ClustSize\",\n",
    "    \"ctx_rh_bankssts_ClustSize\",\n",
    "    \"ctx_rh_caudalanteriorcingulate_ClustSize\",\n",
    "    \"ctx_rh_caudalmiddlefrontal_ClustSize\",\n",
    "    \"ctx_rh_cuneus_ClustSize\",\n",
    "    \"ctx_rh_entorhinal_ClustSize\",\n",
    "    \"ctx_rh_fusiform_ClustSize\",\n",
    "    \"ctx_rh_inferiorparietal_ClustSize\",\n",
    "    \"ctx_rh_inferiortemporal_ClustSize\",\n",
    "    \"ctx_rh_isthmuscingulate_ClustSize\",\n",
    "    \"ctx_rh_lateraloccipital_ClustSize\",\n",
    "    \"ctx_rh_lateralorbitofrontal_ClustSize\",\n",
    "    \"ctx_rh_lingual_ClustSize\",\n",
    "    \"ctx_rh_medialorbitofrontal_ClustSize\",\n",
    "    \"ctx_rh_middletemporal_ClustSize\",\n",
    "    \"ctx_rh_parahippocampal_ClustSize\",\n",
    "    \"ctx_rh_paracentral_ClustSize\",\n",
    "    \"ctx_rh_parsopercularis_ClustSize\",\n",
    "    \"ctx_rh_parsorbitalis_ClustSize\",\n",
    "    \"ctx_rh_parstriangularis_ClustSize\",\n",
    "    \"ctx_rh_pericalcarine_ClustSize\",\n",
    "    \"ctx_rh_postcentral_ClustSize\",\n",
    "    \"ctx_rh_posteriorcingulate_ClustSize\",\n",
    "    \"ctx_rh_precentral_ClustSize\",\n",
    "    \"ctx_rh_precuneus_ClustSize\",\n",
    "    \"ctx_rh_rostralanteriorcingulate_ClustSize\",\n",
    "    \"ctx_rh_rostralmiddlefrontal_ClustSize\",\n",
    "    \"ctx_rh_superiorfrontal_ClustSize\",\n",
    "    \"ctx_rh_superiorparietal_ClustSize\",\n",
    "    \"ctx_rh_superiortemporal_ClustSize\",\n",
    "    \"ctx_rh_supramarginal_ClustSize\",\n",
    "    \"ctx_rh_frontalpole_ClustSize\",\n",
    "    \"ctx_rh_temporalpole_ClustSize\",\n",
    "    \"ctx_rh_transversetemporal_ClustSize\",\n",
    "    \"ctx_rh_insula_ClustSize\",\n",
    "]\n",
    "qrep_dat[tracer] = qrep_dat[tracer][cols_in_order]\n",
    "\n",
    "# Save the output dataframe\n",
    "qreport_files[tracer] = op.join(\n",
    "    qreport_dir,\n",
    "    f\"LEADS-PETCore-quarterly-report_{report_period}_{tracer.upper()}-ROI-means_{today}.csv\",\n",
    ")\n",
    "if save_output:\n",
    "    if overwrite or not op.isfile(qreport_files[tracer]):\n",
    "        qrep_dat[tracer].to_csv(qreport_files[tracer], index=False)\n",
    "        print(f\"Saved {qreport_files[tracer]}\")\n",
    "\n",
    "print(f\"{tracer.upper()}: {qrep_dat[tracer].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /mnt/coredata/processing/leads/data/extraction/quarterly_report_files/LEADS-PETCore-quarterly-report_2024-Q2_FDG-ROI-means_2024-07-10.csv\n",
      "FDG: (154, 232)\n"
     ]
    }
   ],
   "source": [
    "tracer = \"fdg\"\n",
    "save_output = True\n",
    "overwrite = False\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_cols = [\n",
    "    \"tracer\",\n",
    "    \"pet_scan_number\",\n",
    "    \"n_pet_scans\",\n",
    "    \"days_from_baseline_pet\",\n",
    "    \"days_from_last_pet\",\n",
    "    \"pet_res\",\n",
    "    \"mri_date\",\n",
    "    \"mri_image_id\",\n",
    "    \"days_mri_to_pet\",\n",
    "    \"abs_days_mri_to_pet\",\n",
    "    \"pet_proc_dir\",\n",
    "    \"pet_qc_pass\",\n",
    "    \"native_pet_ok\",\n",
    "    \"pet_to_mri_coreg_ok\",\n",
    "    \"pons_mask_ok\",\n",
    "    \"warped_pet_ok\",\n",
    "    \"pet_qc_notes\",\n",
    "    \"mri_qc_pass\",\n",
    "    \"native_nu_rating\",\n",
    "    \"aparc+aseg_rating\",\n",
    "    \"warped_nu_ok\",\n",
    "    \"mri_qc_notes\",\n",
    "    \"qc_pass\",\n",
    "    \"pons_MRIBASED_SUVR\",\n",
    "    \"meta_temporal_MRIBASED_SUVR\",\n",
    "    \"mtl_no_hippocampus_MRIBASED_SUVR\",\n",
    "    \"basolateral_temporal_MRIBASED_SUVR\",\n",
    "    \"temporoparietal_MRIBASED_SUVR\",\n",
    "    \"cortex_desikan_MRIBASED_SUVR\",\n",
    "    \"pons_ClustSize\",\n",
    "    \"meta_temporal_ClustSize\",\n",
    "    \"mtl_no_hippocampus_ClustSize\",\n",
    "    \"basolateral_temporal_ClustSize\",\n",
    "    \"temporoparietal_ClustSize\",\n",
    "    \"cortex_desikan_ClustSize\",\n",
    "]\n",
    "qrep_dat[tracer] = qrep_dat[tracer].drop(columns=drop_cols)\n",
    "\n",
    "# Rename columns\n",
    "qrep_dat[tracer] = qrep_dat[tracer].rename(\n",
    "    columns={\n",
    "        \"subject_id\": \"ID\",\n",
    "        \"pet_date\": \"FDGPET_Date\",\n",
    "        \"pet_image_id\": \"ImageID\",\n",
    "        \"ScalingFactor_pons\": \"ScalingFactor_Pons\",\n",
    "        \"3rd_Ventricle_MRIBASED_SUVR\": \"Third_Ventricle_MRIBASED_SUVR\",\n",
    "        \"4th_Ventricle_MRIBASED_SUVR\": \"Fourth_Ventricle_MRIBASED_SUVR\",\n",
    "        \"3rd_Ventricle_ClustSize\": \"Third_Ventricle_ClustSize\",\n",
    "        \"4th_Ventricle_ClustSize\": \"Fourth_Ventricle_ClustSize\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add empty columns\n",
    "add_cols = [\n",
    "    \"Left_vessel_MRIBASED_SUVR\",\n",
    "    \"Right_vessel_MRIBASED_SUVR\",\n",
    "    \"Fifth_Ventricle_MRIBASED_SUVR\",\n",
    "    \"non_WM_hypointensities_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_unknown_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_unknown_MRIBASED_SUVR\",\n",
    "    \"ScalingFactor_Pons_ClustSize\",\n",
    "    \"Left_vessel_ClustSize\",\n",
    "    \"Right_vessel_ClustSize\",\n",
    "    \"Fifth_Ventricle_ClustSize\",\n",
    "    \"non_WM_hypointensities_ClustSize\",\n",
    "    \"ctx_lh_unknown_ClustSize\",\n",
    "    \"ctx_rh_unknown_ClustSize\",\n",
    "]\n",
    "for col in add_cols:\n",
    "    qrep_dat[tracer][col] = np.nan\n",
    "\n",
    "# Reorder columns\n",
    "cols_in_order = [\n",
    "    \"ID\",\n",
    "    \"FDGPET_Date\",\n",
    "    \"ImageID\",\n",
    "    \"CohortAssgn\",\n",
    "    \"ScalingFactor_Pons\",\n",
    "    \"Left_Cerebral_White_Matter_MRIBASED_SUVR\",\n",
    "    \"Left_Lateral_Ventricle_MRIBASED_SUVR\",\n",
    "    \"Left_Inf_Lat_Vent_MRIBASED_SUVR\",\n",
    "    \"Left_Cerebellum_White_Matter_MRIBASED_SUVR\",\n",
    "    \"Left_Cerebellum_Cortex_MRIBASED_SUVR\",\n",
    "    \"Left_Thalamus_Proper_MRIBASED_SUVR\",\n",
    "    \"Left_Caudate_MRIBASED_SUVR\",\n",
    "    \"Left_Putamen_MRIBASED_SUVR\",\n",
    "    \"Left_Pallidum_MRIBASED_SUVR\",\n",
    "    \"Third_Ventricle_MRIBASED_SUVR\",\n",
    "    \"Fourth_Ventricle_MRIBASED_SUVR\",\n",
    "    \"Brain_Stem_MRIBASED_SUVR\",\n",
    "    \"Left_Hippocampus_MRIBASED_SUVR\",\n",
    "    \"Left_Amygdala_MRIBASED_SUVR\",\n",
    "    \"CSF_MRIBASED_SUVR\",\n",
    "    \"Left_Accumbens_area_MRIBASED_SUVR\",\n",
    "    \"Left_VentralDC_MRIBASED_SUVR\",\n",
    "    \"Left_vessel_MRIBASED_SUVR\",\n",
    "    \"Left_choroid_plexus_MRIBASED_SUVR\",\n",
    "    \"Right_Cerebral_White_Matter_MRIBASED_SUVR\",\n",
    "    \"Right_Lateral_Ventricle_MRIBASED_SUVR\",\n",
    "    \"Right_Inf_Lat_Vent_MRIBASED_SUVR\",\n",
    "    \"Right_Cerebellum_White_Matter_MRIBASED_SUVR\",\n",
    "    \"Right_Cerebellum_Cortex_MRIBASED_SUVR\",\n",
    "    \"Right_Thalamus_Proper_MRIBASED_SUVR\",\n",
    "    \"Right_Caudate_MRIBASED_SUVR\",\n",
    "    \"Right_Putamen_MRIBASED_SUVR\",\n",
    "    \"Right_Pallidum_MRIBASED_SUVR\",\n",
    "    \"Right_Hippocampus_MRIBASED_SUVR\",\n",
    "    \"Right_Amygdala_MRIBASED_SUVR\",\n",
    "    \"Right_Accumbens_area_MRIBASED_SUVR\",\n",
    "    \"Right_VentralDC_MRIBASED_SUVR\",\n",
    "    \"Right_vessel_MRIBASED_SUVR\",\n",
    "    \"Right_choroid_plexus_MRIBASED_SUVR\",\n",
    "    \"Fifth_Ventricle_MRIBASED_SUVR\",\n",
    "    \"WM_hypointensities_MRIBASED_SUVR\",\n",
    "    \"non_WM_hypointensities_MRIBASED_SUVR\",\n",
    "    \"Optic_Chiasm_MRIBASED_SUVR\",\n",
    "    \"CC_Posterior_MRIBASED_SUVR\",\n",
    "    \"CC_Mid_Posterior_MRIBASED_SUVR\",\n",
    "    \"CC_Central_MRIBASED_SUVR\",\n",
    "    \"CC_Mid_Anterior_MRIBASED_SUVR\",\n",
    "    \"CC_Anterior_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_unknown_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_bankssts_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_caudalanteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_caudalmiddlefrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_cuneus_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_entorhinal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_fusiform_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_inferiorparietal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_inferiortemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_isthmuscingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_lateraloccipital_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_lateralorbitofrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_lingual_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_medialorbitofrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_middletemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_parahippocampal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_paracentral_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_parsopercularis_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_parsorbitalis_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_parstriangularis_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_pericalcarine_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_postcentral_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_posteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_precentral_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_precuneus_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_rostralanteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_rostralmiddlefrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_superiorfrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_superiorparietal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_superiortemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_supramarginal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_frontalpole_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_temporalpole_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_transversetemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_lh_insula_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_unknown_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_bankssts_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_caudalanteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_caudalmiddlefrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_cuneus_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_entorhinal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_fusiform_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_inferiorparietal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_inferiortemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_isthmuscingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_lateraloccipital_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_lateralorbitofrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_lingual_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_medialorbitofrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_middletemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_parahippocampal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_paracentral_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_parsopercularis_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_parsorbitalis_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_parstriangularis_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_pericalcarine_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_postcentral_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_posteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_precentral_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_precuneus_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_rostralanteriorcingulate_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_rostralmiddlefrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_superiorfrontal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_superiorparietal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_superiortemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_supramarginal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_frontalpole_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_temporalpole_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_transversetemporal_MRIBASED_SUVR\",\n",
    "    \"ctx_rh_insula_MRIBASED_SUVR\",\n",
    "    \"ScalingFactor_Pons_ClustSize\",\n",
    "    \"Left_Cerebral_White_Matter_ClustSize\",\n",
    "    \"Left_Lateral_Ventricle_ClustSize\",\n",
    "    \"Left_Inf_Lat_Vent_ClustSize\",\n",
    "    \"Left_Cerebellum_White_Matter_ClustSize\",\n",
    "    \"Left_Cerebellum_Cortex_ClustSize\",\n",
    "    \"Left_Thalamus_Proper_ClustSize\",\n",
    "    \"Left_Caudate_ClustSize\",\n",
    "    \"Left_Putamen_ClustSize\",\n",
    "    \"Left_Pallidum_ClustSize\",\n",
    "    \"Third_Ventricle_ClustSize\",\n",
    "    \"Fourth_Ventricle_ClustSize\",\n",
    "    \"Brain_Stem_ClustSize\",\n",
    "    \"Left_Hippocampus_ClustSize\",\n",
    "    \"Left_Amygdala_ClustSize\",\n",
    "    \"CSF_ClustSize\",\n",
    "    \"Left_Accumbens_area_ClustSize\",\n",
    "    \"Left_VentralDC_ClustSize\",\n",
    "    \"Left_vessel_ClustSize\",\n",
    "    \"Left_choroid_plexus_ClustSize\",\n",
    "    \"Right_Cerebral_White_Matter_ClustSize\",\n",
    "    \"Right_Lateral_Ventricle_ClustSize\",\n",
    "    \"Right_Inf_Lat_Vent_ClustSize\",\n",
    "    \"Right_Cerebellum_White_Matter_ClustSize\",\n",
    "    \"Right_Cerebellum_Cortex_ClustSize\",\n",
    "    \"Right_Thalamus_Proper_ClustSize\",\n",
    "    \"Right_Caudate_ClustSize\",\n",
    "    \"Right_Putamen_ClustSize\",\n",
    "    \"Right_Pallidum_ClustSize\",\n",
    "    \"Right_Hippocampus_ClustSize\",\n",
    "    \"Right_Amygdala_ClustSize\",\n",
    "    \"Right_Accumbens_area_ClustSize\",\n",
    "    \"Right_VentralDC_ClustSize\",\n",
    "    \"Right_vessel_ClustSize\",\n",
    "    \"Right_choroid_plexus_ClustSize\",\n",
    "    \"Fifth_Ventricle_ClustSize\",\n",
    "    \"WM_hypointensities_ClustSize\",\n",
    "    \"non_WM_hypointensities_ClustSize\",\n",
    "    \"Optic_Chiasm_ClustSize\",\n",
    "    \"CC_Posterior_ClustSize\",\n",
    "    \"CC_Mid_Posterior_ClustSize\",\n",
    "    \"CC_Central_ClustSize\",\n",
    "    \"CC_Mid_Anterior_ClustSize\",\n",
    "    \"CC_Anterior_ClustSize\",\n",
    "    \"ctx_lh_unknown_ClustSize\",\n",
    "    \"ctx_lh_bankssts_ClustSize\",\n",
    "    \"ctx_lh_caudalanteriorcingulate_ClustSize\",\n",
    "    \"ctx_lh_caudalmiddlefrontal_ClustSize\",\n",
    "    \"ctx_lh_cuneus_ClustSize\",\n",
    "    \"ctx_lh_entorhinal_ClustSize\",\n",
    "    \"ctx_lh_fusiform_ClustSize\",\n",
    "    \"ctx_lh_inferiorparietal_ClustSize\",\n",
    "    \"ctx_lh_inferiortemporal_ClustSize\",\n",
    "    \"ctx_lh_isthmuscingulate_ClustSize\",\n",
    "    \"ctx_lh_lateraloccipital_ClustSize\",\n",
    "    \"ctx_lh_lateralorbitofrontal_ClustSize\",\n",
    "    \"ctx_lh_lingual_ClustSize\",\n",
    "    \"ctx_lh_medialorbitofrontal_ClustSize\",\n",
    "    \"ctx_lh_middletemporal_ClustSize\",\n",
    "    \"ctx_lh_parahippocampal_ClustSize\",\n",
    "    \"ctx_lh_paracentral_ClustSize\",\n",
    "    \"ctx_lh_parsopercularis_ClustSize\",\n",
    "    \"ctx_lh_parsorbitalis_ClustSize\",\n",
    "    \"ctx_lh_parstriangularis_ClustSize\",\n",
    "    \"ctx_lh_pericalcarine_ClustSize\",\n",
    "    \"ctx_lh_postcentral_ClustSize\",\n",
    "    \"ctx_lh_posteriorcingulate_ClustSize\",\n",
    "    \"ctx_lh_precentral_ClustSize\",\n",
    "    \"ctx_lh_precuneus_ClustSize\",\n",
    "    \"ctx_lh_rostralanteriorcingulate_ClustSize\",\n",
    "    \"ctx_lh_rostralmiddlefrontal_ClustSize\",\n",
    "    \"ctx_lh_superiorfrontal_ClustSize\",\n",
    "    \"ctx_lh_superiorparietal_ClustSize\",\n",
    "    \"ctx_lh_superiortemporal_ClustSize\",\n",
    "    \"ctx_lh_supramarginal_ClustSize\",\n",
    "    \"ctx_lh_frontalpole_ClustSize\",\n",
    "    \"ctx_lh_temporalpole_ClustSize\",\n",
    "    \"ctx_lh_transversetemporal_ClustSize\",\n",
    "    \"ctx_lh_insula_ClustSize\",\n",
    "    \"ctx_rh_unknown_ClustSize\",\n",
    "    \"ctx_rh_bankssts_ClustSize\",\n",
    "    \"ctx_rh_caudalanteriorcingulate_ClustSize\",\n",
    "    \"ctx_rh_caudalmiddlefrontal_ClustSize\",\n",
    "    \"ctx_rh_cuneus_ClustSize\",\n",
    "    \"ctx_rh_entorhinal_ClustSize\",\n",
    "    \"ctx_rh_fusiform_ClustSize\",\n",
    "    \"ctx_rh_inferiorparietal_ClustSize\",\n",
    "    \"ctx_rh_inferiortemporal_ClustSize\",\n",
    "    \"ctx_rh_isthmuscingulate_ClustSize\",\n",
    "    \"ctx_rh_lateraloccipital_ClustSize\",\n",
    "    \"ctx_rh_lateralorbitofrontal_ClustSize\",\n",
    "    \"ctx_rh_lingual_ClustSize\",\n",
    "    \"ctx_rh_medialorbitofrontal_ClustSize\",\n",
    "    \"ctx_rh_middletemporal_ClustSize\",\n",
    "    \"ctx_rh_parahippocampal_ClustSize\",\n",
    "    \"ctx_rh_paracentral_ClustSize\",\n",
    "    \"ctx_rh_parsopercularis_ClustSize\",\n",
    "    \"ctx_rh_parsorbitalis_ClustSize\",\n",
    "    \"ctx_rh_parstriangularis_ClustSize\",\n",
    "    \"ctx_rh_pericalcarine_ClustSize\",\n",
    "    \"ctx_rh_postcentral_ClustSize\",\n",
    "    \"ctx_rh_posteriorcingulate_ClustSize\",\n",
    "    \"ctx_rh_precentral_ClustSize\",\n",
    "    \"ctx_rh_precuneus_ClustSize\",\n",
    "    \"ctx_rh_rostralanteriorcingulate_ClustSize\",\n",
    "    \"ctx_rh_rostralmiddlefrontal_ClustSize\",\n",
    "    \"ctx_rh_superiorfrontal_ClustSize\",\n",
    "    \"ctx_rh_superiorparietal_ClustSize\",\n",
    "    \"ctx_rh_superiortemporal_ClustSize\",\n",
    "    \"ctx_rh_supramarginal_ClustSize\",\n",
    "    \"ctx_rh_frontalpole_ClustSize\",\n",
    "    \"ctx_rh_temporalpole_ClustSize\",\n",
    "    \"ctx_rh_transversetemporal_ClustSize\",\n",
    "    \"ctx_rh_insula_ClustSize\",\n",
    "]\n",
    "qrep_dat[tracer] = qrep_dat[tracer][cols_in_order]\n",
    "\n",
    "# Save the output dataframe\n",
    "qreport_files[tracer] = op.join(\n",
    "    qreport_dir,\n",
    "    f\"LEADS-PETCore-quarterly-report_{report_period}_{tracer.upper()}-ROI-means_{today}.csv\",\n",
    ")\n",
    "if save_output:\n",
    "    if overwrite or not op.isfile(qreport_files[tracer]):\n",
    "        qrep_dat[tracer].to_csv(qreport_files[tracer], index=False)\n",
    "        print(f\"Saved {qreport_files[tracer]}\")\n",
    "\n",
    "print(f\"{tracer.upper()}: {qrep_dat[tracer].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipy311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
